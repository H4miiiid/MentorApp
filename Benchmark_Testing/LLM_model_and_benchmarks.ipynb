{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP8mQ46K3duLLQ+36maTfWb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"55OEHBb41i7n","executionInfo":{"status":"ok","timestamp":1761657271236,"user_tz":-60,"elapsed":28785,"user":{"displayName":"hamidreza bahmanyar","userId":"02252184421162584539"}},"outputId":"5996905a-5472-4e57-cf88-8328d2e170bb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n"]},{"cell_type":"code","source":["!pip uninstall -y bitsandbytes triton torch torchvision torchaudio transformers accelerate\n","!pip install torch==2.3.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n","!pip install -U bitsandbytes==0.43.1\n","!pip install -U triton==3.0.0\n","!pip install -U transformers==4.44.2 accelerate==0.34.2\n","\n","# Setup model directory\n","import os\n","model_name = \"mistralai/Mistral-7B-Instruct-v0.3\"\n","save_dir = \"/content/drive/MyDrive/LLM_model/mistral_7b_quantized\"\n","os.makedirs(save_dir, exist_ok=True)\n","\n","print(\"✅ Environment ready. Now rerun your model download cell next.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"BzCKuyde73f_","executionInfo":{"status":"ok","timestamp":1761136956786,"user_tz":-120,"elapsed":91230,"user":{"displayName":"hamidreza bahmanyar","userId":"02252184421162584539"}},"outputId":"eabe616e-daae-481a-8084-d325c86e10ee"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: bitsandbytes 0.43.1\n","Uninstalling bitsandbytes-0.43.1:\n","  Successfully uninstalled bitsandbytes-0.43.1\n","Found existing installation: triton 3.5.0\n","Uninstalling triton-3.5.0:\n","  Successfully uninstalled triton-3.5.0\n","Found existing installation: torch 2.3.0+cu121\n","Uninstalling torch-2.3.0+cu121:\n","  Successfully uninstalled torch-2.3.0+cu121\n","Found existing installation: torchvision 0.18.0+cu121\n","Uninstalling torchvision-0.18.0+cu121:\n","  Successfully uninstalled torchvision-0.18.0+cu121\n","Found existing installation: torchaudio 2.3.0+cu121\n","Uninstalling torchaudio-2.3.0+cu121:\n","  Successfully uninstalled torchaudio-2.3.0+cu121\n","Found existing installation: transformers 4.57.1\n","Uninstalling transformers-4.57.1:\n","  Successfully uninstalled transformers-4.57.1\n","Found existing installation: accelerate 1.10.1\n","Uninstalling accelerate-1.10.1:\n","  Successfully uninstalled accelerate-1.10.1\n","Looking in indexes: https://download.pytorch.org/whl/cu121\n","Collecting torch==2.3.0\n","  Using cached https://download.pytorch.org/whl/cu121/torch-2.3.0%2Bcu121-cp312-cp312-linux_x86_64.whl (780.9 MB)\n","Collecting torchvision\n","  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp312-cp312-linux_x86_64.whl (7.3 MB)\n","Collecting torchaudio\n","  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (4.15.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (12.1.105)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0) (12.6.85)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n","INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n","Collecting torchvision\n","  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.20.0%2Bcu121-cp312-cp312-linux_x86_64.whl (7.3 MB)\n","  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.19.1%2Bcu121-cp312-cp312-linux_x86_64.whl (7.1 MB)\n","  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.19.0%2Bcu121-cp312-cp312-linux_x86_64.whl (7.1 MB)\n","  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.18.1%2Bcu121-cp312-cp312-linux_x86_64.whl (7.0 MB)\n","  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.18.0%2Bcu121-cp312-cp312-linux_x86_64.whl (7.0 MB)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n","INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n","Collecting torchaudio\n","  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.5.0%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\n","  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.4.1%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\n","  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.4.0%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\n","  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.3.1%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\n","  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.3.0%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.3.0) (3.0.3)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.3.0) (1.3.0)\n","Installing collected packages: torch, torchvision, torchaudio\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","sentence-transformers 5.1.1 requires transformers<5.0.0,>=4.41.0, which is not installed.\n","peft 0.17.1 requires accelerate>=0.21.0, which is not installed.\n","peft 0.17.1 requires transformers, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed torch-2.3.0+cu121 torchaudio-2.3.0+cu121 torchvision-0.18.0+cu121\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["torch","torchgen","torchvision"]},"id":"6d07fb9fcccf46289a194c717638b69c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting bitsandbytes==0.43.1\n","  Using cached bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from bitsandbytes==0.43.1) (2.3.0+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from bitsandbytes==0.43.1) (2.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.43.1) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.43.1) (4.15.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.43.1) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.43.1) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.43.1) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.43.1) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.43.1) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.43.1) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.43.1) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.43.1) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.43.1) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.43.1) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.43.1) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.43.1) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.43.1) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.43.1) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.43.1) (12.1.105)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes==0.43.1) (12.6.85)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->bitsandbytes==0.43.1) (3.0.3)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch->bitsandbytes==0.43.1) (1.3.0)\n","Using cached bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n","Installing collected packages: bitsandbytes\n","Successfully installed bitsandbytes-0.43.1\n","Collecting triton==3.0.0\n","  Downloading triton-3.0.0-1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from triton==3.0.0) (3.20.0)\n","Downloading triton-3.0.0-1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: triton\n","Successfully installed triton-3.0.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["triton"]},"id":"87879f84740245b396c57eadbc1832ef"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting transformers==4.44.2\n","  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting accelerate==0.34.2\n","  Downloading accelerate-0.34.2-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (3.20.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (0.35.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (2.32.4)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (0.6.2)\n","Collecting tokenizers<0.20,>=0.19 (from transformers==4.44.2)\n","  Downloading tokenizers-0.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate==0.34.2) (5.9.5)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.34.2) (2.3.0+cu121)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (1.1.10)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.105)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.34.2) (12.6.85)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (2025.10.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.34.2) (3.0.3)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch>=1.10.0->accelerate==0.34.2) (1.3.0)\n","Downloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m108.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading accelerate-0.34.2-py3-none-any.whl (324 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.4/324.4 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tokenizers-0.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m126.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tokenizers, transformers, accelerate\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.22.1\n","    Uninstalling tokenizers-0.22.1:\n","      Successfully uninstalled tokenizers-0.22.1\n","Successfully installed accelerate-0.34.2 tokenizers-0.19.1 transformers-4.44.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["accelerate","tokenizers","transformers"]},"id":"89a15044375c40469a5057afa6269ca3"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","✅ Environment ready. Now rerun your model download cell next.\n"]}]},{"cell_type":"code","source":["!pip install torch==2.3.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n","!pip install -U bitsandbytes==0.43.1\n","!pip install -U triton==3.0.0\n","!pip install -U transformers==4.44.2 accelerate==0.34.2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"gN4FBtHmOpSW","executionInfo":{"status":"ok","timestamp":1761229205593,"user_tz":-120,"elapsed":284064,"user":{"displayName":"hamidreza bahmanyar","userId":"02252184421162584539"}},"outputId":"355278e2-d683-4a3a-9823-d1ee75a01e48"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://download.pytorch.org/whl/cu121\n","Collecting torch==2.3.0\n","  Downloading https://download.pytorch.org/whl/cu121/torch-2.3.0%2Bcu121-cp312-cp312-linux_x86_64.whl (780.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.9/780.9 MB\u001b[0m \u001b[31m845.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (4.15.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (2025.3.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m105.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m122.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0) (12.6.85)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n","INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n","Collecting torchvision\n","  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp312-cp312-linux_x86_64.whl (7.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.20.0%2Bcu121-cp312-cp312-linux_x86_64.whl (7.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m105.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.19.1%2Bcu121-cp312-cp312-linux_x86_64.whl (7.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m107.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.19.0%2Bcu121-cp312-cp312-linux_x86_64.whl (7.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m108.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.18.1%2Bcu121-cp312-cp312-linux_x86_64.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.18.0%2Bcu121-cp312-cp312-linux_x86_64.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n","INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n","Collecting torchaudio\n","  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.5.0%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m102.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.4.1%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.4.0%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.3.1%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.3.0%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.3.0) (3.0.3)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.3.0) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n","  Attempting uninstall: nvidia-nvtx-cu12\n","    Found existing installation: nvidia-nvtx-cu12 12.6.77\n","    Uninstalling nvidia-nvtx-cu12-12.6.77:\n","      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.27.3\n","    Uninstalling nvidia-nccl-cu12-2.27.3:\n","      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n","    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.7.77\n","    Uninstalling nvidia-curand-cu12-10.3.7.77:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n","    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n","      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n","    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n","    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n","    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n","      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n","    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n","    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.8.0+cu126\n","    Uninstalling torch-2.8.0+cu126:\n","      Successfully uninstalled torch-2.8.0+cu126\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.23.0+cu126\n","    Uninstalling torchvision-0.23.0+cu126:\n","      Successfully uninstalled torchvision-0.23.0+cu126\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 2.8.0+cu126\n","    Uninstalling torchaudio-2.8.0+cu126:\n","      Successfully uninstalled torchaudio-2.8.0+cu126\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.3.0+cu121 torchaudio-2.3.0+cu121 torchvision-0.18.0+cu121\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["torch","torchgen"]},"id":"ecd50b4e23df4345ab8fef0583208559"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting bitsandbytes==0.43.1\n","  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from bitsandbytes==0.43.1) (2.3.0+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from bitsandbytes==0.43.1) (2.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.43.1) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.43.1) (4.15.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.43.1) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.43.1) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.43.1) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.43.1) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.43.1) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.43.1) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.43.1) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.43.1) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.43.1) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.43.1) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.43.1) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.43.1) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.43.1) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.43.1) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->bitsandbytes==0.43.1) (12.1.105)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes==0.43.1) (12.6.85)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->bitsandbytes==0.43.1) (3.0.3)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch->bitsandbytes==0.43.1) (1.3.0)\n","Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: bitsandbytes\n","Successfully installed bitsandbytes-0.43.1\n","Collecting triton==3.0.0\n","  Downloading triton-3.0.0-1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from triton==3.0.0) (3.20.0)\n","Downloading triton-3.0.0-1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m425.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: triton\n","  Attempting uninstall: triton\n","    Found existing installation: triton 3.4.0\n","    Uninstalling triton-3.4.0:\n","      Successfully uninstalled triton-3.4.0\n","Successfully installed triton-3.0.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["triton"]},"id":"a6169768d9c44eacb09a1a4608816240"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting transformers==4.44.2\n","  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting accelerate==0.34.2\n","  Downloading accelerate-0.34.2-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (3.20.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (0.35.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (2.32.4)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (0.6.2)\n","Collecting tokenizers<0.20,>=0.19 (from transformers==4.44.2)\n","  Downloading tokenizers-0.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate==0.34.2) (5.9.5)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.34.2) (2.3.0+cu121)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (1.1.10)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (12.1.105)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.34.2) (12.6.85)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (2025.10.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.34.2) (3.0.3)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch>=1.10.0->accelerate==0.34.2) (1.3.0)\n","Downloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading accelerate-0.34.2-py3-none-any.whl (324 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.4/324.4 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tokenizers-0.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m123.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tokenizers, transformers, accelerate\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.22.1\n","    Uninstalling tokenizers-0.22.1:\n","      Successfully uninstalled tokenizers-0.22.1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.57.1\n","    Uninstalling transformers-4.57.1:\n","      Successfully uninstalled transformers-4.57.1\n","  Attempting uninstall: accelerate\n","    Found existing installation: accelerate 1.11.0\n","    Uninstalling accelerate-1.11.0:\n","      Successfully uninstalled accelerate-1.11.0\n","Successfully installed accelerate-0.34.2 tokenizers-0.19.1 transformers-4.44.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["accelerate","tokenizers","transformers"]},"id":"85eddc7bfb4549e3a3c488561332b43b"}},"metadata":{}}]},{"cell_type":"markdown","source":["## 1. Download the model and upload it to the Google Drive to avoid to download it everytime. (Just Once)"],"metadata":{"id":"xOMTHEUMDcfW"}},{"cell_type":"code","source":["from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n","import os\n","\n","model_name = \"mistralai/Mistral-7B-Instruct-v0.3\"\n","save_dir = \"/content/drive/MyDrive/LLM_model/mistral_7b_quantized\"\n","os.makedirs(save_dir, exist_ok=True)\n","\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_compute_dtype=\"float16\"\n",")\n","\n","print(\"Downloading and quantizing model...\")\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    quantization_config=bnb_config,\n","    device_map=\"auto\"\n",")\n","\n","print(\"Saving model to Google Drive...\")\n","model.save_pretrained(save_dir)\n","tokenizer.save_pretrained(save_dir)\n","\n","print(f\"Done! Model saved to: {save_dir}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"Db2IrpWd2Di4","executionInfo":{"status":"error","timestamp":1761221030014,"user_tz":-120,"elapsed":5102,"user":{"displayName":"hamidreza bahmanyar","userId":"02252184421162584539"}},"outputId":"be81d381-8025-489b-e2fe-1dde71098f50"},"execution_count":2,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2108926048.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBitsAndBytesConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"mistralai/Mistral-7B-Instruct-v0.3\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msave_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/LLM_model/mistral_7b_quantized\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Check the dependencies satisfy the minimal versions required.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdependency_versions_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m from .utils import (\n\u001b[1;32m     29\u001b[0m     \u001b[0mOptionalDependencyNotAvailable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/dependency_versions_check.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdependency_versions_table\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequire_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_version_core\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m )\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackbone_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBackboneConfigMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBackboneMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mchat_template_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDocstringParsingException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeHintParsingException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_json_schema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIMAGENET_DEFAULT_MEAN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGENET_DEFAULT_STD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGENET_STANDARD_MEAN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGENET_STANDARD_STD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m from .doc import (\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["## After downloading and upload it to the drive, we can use this function to load the model everytime without downloading it everytime."],"metadata":{"id":"_OJmDzslDsyW"}},{"cell_type":"code","source":["def load_mistral_from_drive(base_dir=\"/content/drive/MyDrive/LLM_model/mistral_7b_quantized\"):\n","    from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n","\n","    bnb_config = BitsAndBytesConfig(\n","        load_in_4bit=True,\n","        bnb_4bit_quant_type=\"nf4\",\n","        bnb_4bit_use_double_quant=True,\n","        bnb_4bit_compute_dtype=\"float16\"\n","    )\n","\n","    tokenizer = AutoTokenizer.from_pretrained(base_dir)\n","    model = AutoModelForCausalLM.from_pretrained(\n","        base_dir,\n","        quantization_config=bnb_config,\n","        device_map=\"auto\"\n","    )\n","    return model, tokenizer\n","\n","\n","model, tokenizer = load_mistral_from_drive()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"CViuj4Fs3XGy","executionInfo":{"status":"error","timestamp":1761228914352,"user_tz":-120,"elapsed":12875,"user":{"displayName":"hamidreza bahmanyar","userId":"02252184421162584539"}},"outputId":"0b8339c5-816c-4570-f458-f75dc6902bc4"},"execution_count":2,"outputs":[{"output_type":"error","ename":"PackageNotFoundError","evalue":"No package metadata was found for bitsandbytes","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mfrom_name\u001b[0;34m(cls, name)\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mStopIteration\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mPackageNotFoundError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3843652190.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_mistral_from_drive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipython-input-3843652190.py\u001b[0m in \u001b[0;36mload_mistral_from_drive\u001b[0;34m(base_dir)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBitsAndBytesConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     bnb_config = BitsAndBytesConfig(\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mload_in_4bit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mbnb_4bit_quant_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nf4\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/quantization_config.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, load_in_8bit, load_in_4bit, llm_int8_threshold, llm_int8_skip_modules, llm_int8_enable_fp32_cpu_offload, llm_int8_has_fp16_weight, bnb_4bit_compute_dtype, bnb_4bit_quant_type, bnb_4bit_use_double_quant, bnb_4bit_quant_storage, **kwargs)\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unused kwargs: {list(kwargs.keys())}. These kwargs are not used in {self.__class__}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/quantization_config.py\u001b[0m in \u001b[0;36mpost_init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    566\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bnb_4bit_use_double_quant must be a boolean\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m         if self.load_in_4bit and not version.parse(importlib.metadata.version(\"bitsandbytes\")) >= version.parse(\n\u001b[0m\u001b[1;32m    569\u001b[0m             \u001b[0;34m\"0.39.0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         ):\n","\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mversion\u001b[0;34m(distribution_name)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;34m\"Version\"\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m     \"\"\"\n\u001b[0;32m--> 889\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistribution_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mdistribution\u001b[0;34m(distribution_name)\u001b[0m\n\u001b[1;32m    860\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDistribution\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mor\u001b[0m \u001b[0msubclass\u001b[0m \u001b[0mthereof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m     \"\"\"\n\u001b[0;32m--> 862\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistribution_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mfrom_name\u001b[0;34m(cls, name)\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPackageNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mPackageNotFoundError\u001b[0m: No package metadata was found for bitsandbytes","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"markdown","source":["## 2. Clone the Aider Polyglot benchmark for evaluating the LLM Mistral 7B model with Python codes."],"metadata":{"id":"-fazCjRZD7ut"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive\n","!git clone --no-checkout https://github.com/Aider-AI/polyglot-benchmark.git\n","%cd polyglot-benchmark\n","!git sparse-checkout init --cone\n","!git sparse-checkout set python/exercises/practice\n","!git checkout main\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qwJ9nsBf_saX","executionInfo":{"status":"ok","timestamp":1761138739666,"user_tz":-120,"elapsed":5567,"user":{"displayName":"hamidreza bahmanyar","userId":"02252184421162584539"}},"outputId":"2163448c-ac64-4cd7-b7af-a47d465460b8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive\n","Cloning into 'polyglot-benchmark'...\n","remote: Enumerating objects: 2759, done.\u001b[K\n","remote: Counting objects: 100% (2759/2759), done.\u001b[K\n","remote: Compressing objects: 100% (1929/1929), done.\u001b[K\n","remote: Total 2759 (delta 375), reused 2757 (delta 373), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (2759/2759), 1.06 MiB | 3.78 MiB/s, done.\n","Resolving deltas: 100% (375/375), done.\n","/content/drive/MyDrive/polyglot-benchmark\n","Updating files: 100% (281/281), done.\n","Already on 'main'\n","Your branch is up to date with 'origin/main'.\n"]}]},{"cell_type":"code","source":["!ls /content/drive/MyDrive/polyglot-benchmark/python/exercises/practice | head\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EjIbJBwyDHMK","executionInfo":{"status":"ok","timestamp":1761138785148,"user_tz":-120,"elapsed":118,"user":{"displayName":"hamidreza bahmanyar","userId":"02252184421162584539"}},"outputId":"8f8f1b65-c3bb-476a-d74c-d1cfae35cd96"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["affine-cipher\n","beer-song\n","book-store\n","bottle-song\n","bowling\n","connect\n","dominoes\n","dot-dsl\n","food-chain\n","forth\n"]}]},{"cell_type":"code","source":["# Test the model\n","from transformers import pipeline\n","\n","pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n","prompt = \"Explain what quantization does in large language models.\"\n","print(pipe(prompt, max_new_tokens=80)[0]['generated_text'])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2pchtGc9QxgH","executionInfo":{"status":"ok","timestamp":1761142354254,"user_tz":-120,"elapsed":28211,"user":{"displayName":"hamidreza bahmanyar","userId":"02252184421162584539"}},"outputId":"7881abe0-f073-40aa-87ec-2019b3fe3a82"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["Explain what quantization does in large language models.\n","\n","Quantization in large language models, such as those used in natural language processing (NLP), is a process that reduces the computational complexity and memory requirements of the model, making it more efficient and practical for deployment on hardware like CPUs and GPUs.\n","\n","In the context of neural networks, which are the foundation of many large language models, quantization involves converting the floating\n"]}]},{"cell_type":"markdown","source":["## 3. Try to test the benchmark and model for one exercise."],"metadata":{"id":"N47jZskA_Gd5"}},{"cell_type":"code","source":["prompt = \"\"\"\n","You are a Python intelligence. You need to read the description below for the project and write the function(s) exactly mentioned in the description in Python.\n","\n","The description of the project: <<>>\n","\n","The function(s) you need to complete. Attention you need to complete the function(s) where written \"pass\":\n","  <<\n","\n","  >>\n","\n","Write only the required Python function(s) replacing the \"pass\" statement(s) with the appropriate code implementing the described functionality. Do not add any explanations, comments, additional functions, or any other content outside the specified function(s). Ensure that the code is executable and runnable as is.\n","\n","# Output Format\n","\n","Provide only valid Python code for the specified function(s), without any surrounding text or extra output.\n","\"\"\""],"metadata":{"id":"2MIKZ02q_-Ek","executionInfo":{"status":"ok","timestamp":1761222288737,"user_tz":-120,"elapsed":55,"user":{"displayName":"hamidreza bahmanyar","userId":"02252184421162584539"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n","\n","# Generate output\n","output_tokens = model.generate(**inputs, max_new_tokens=500, temperature=0.0)\n","\n","# Decode and keep only the new model output (no input echo)\n","generated_text = tokenizer.decode(output_tokens[0], skip_special_tokens=True).replace(prompt, \"\").strip()\n","\n","# If the model returns code blocks, extract just the Python code\n","if \"```python\" in generated_text:\n","    generated_text = generated_text.split(\"```python\")[1].split(\"```\")[0].strip()\n","\n","print(generated_text)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K3ixxTDX_SYc","executionInfo":{"status":"ok","timestamp":1761222331889,"user_tz":-120,"elapsed":34879,"user":{"displayName":"hamidreza bahmanyar","userId":"02252184421162584539"}},"outputId":"2e95aab8-b1e0-4006-ebda-1ff6708317a0"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["def total(basket):\n","    books = set(basket)\n","    if len(books) == 5:\n","        return sum([8 * (1 - 0.25) for _ in basket])\n","\n","    discounts = {\n","        2: 0.05,\n","        3: 0.1,\n","        4: 0.2\n","    }\n","\n","    groups = []\n","    for book in books:\n","        group = []\n","        for b in basket:\n","            if book in (b, *group):\n","                group.append(b)\n","            else:\n","                if group:\n","                    groups.append(group)\n","                    group = [b]\n","                else:\n","                    group.append(b)\n","        if group:\n","            groups.append(group)\n","\n","    total_price = 0\n","    for group in groups:\n","        if len(group) in discounts:\n","            total_price += sum([8 * (1 - discounts[len(group)]) for _ in group])\n","        else:\n","            total_price += sum([8 for _ in group])\n","\n","    return total_price\n"]}]},{"cell_type":"markdown","source":["## 4. Try to use the **instructions.md** files for all exercises to prompt the model to generate the answers."],"metadata":{"id":"4cr0MZp7RKPm"}},{"cell_type":"code","source":["import os\n","import subprocess\n","import torch\n","import pandas as pd\n","\n","# ======================================================\n","# 2️⃣  Benchmark folders\n","# ======================================================\n","bench_dir = \"/content/drive/MyDrive/polyglot-benchmark/python/exercises/practice\"\n","results_log = []\n","\n","# ======================================================\n","# 3️⃣  Helper to run tests\n","# ======================================================\n","def run_pytest(test_file):\n","    \"\"\"Run pytest on the given test file and return (passed, log).\"\"\"\n","    try:\n","        res = subprocess.run(\n","            [\"pytest\", \"-q\", test_file, \"--disable-warnings\", \"--maxfail=1\"],\n","            capture_output=True,\n","            text=True,\n","            timeout=25,\n","            cwd=os.path.dirname(test_file)\n","        )\n","        return res.returncode == 0, res.stdout\n","    except subprocess.TimeoutExpired:\n","        return False, \"Timeout\"\n","    except Exception as e:\n","        return False, str(e)\n","\n","# ======================================================\n","# 4️⃣  Main loop over exercises\n","# ======================================================\n","passed, total = 0, 0\n","\n","for ex in sorted(os.listdir(bench_dir)):\n","    ex_path = os.path.join(bench_dir, ex)\n","    docs_path = os.path.join(ex_path, \".docs\", \"instructions.md\")\n","    append_path = os.path.join(ex_path, \".docs\", \"instructions.append.md\")\n","\n","    # find stub and test files\n","    stub_files = [f for f in os.listdir(ex_path)\n","                  if f.endswith(\".py\") and not f.endswith(\"_test.py\")]\n","    test_files = [f for f in os.listdir(ex_path)\n","                  if f.endswith(\"_test.py\")]\n","\n","    if not (os.path.exists(docs_path) and stub_files and test_files):\n","        continue  # skip if incomplete\n","\n","    total += 1\n","    stub_path = os.path.join(ex_path, stub_files[0])\n","    test_path = os.path.join(ex_path, test_files[0])\n","\n","    # read content\n","    with open(docs_path) as f:\n","        desc = f.read()\n","    append_text = \"\"\n","    if os.path.exists(append_path):\n","        with open(append_path) as f:\n","            append_text = f.read()\n","    with open(stub_path) as f:\n","        stub_code = f.read()\n","\n","    # ==================================================\n","    # Build strong prompt\n","    # ==================================================\n","    prompt = f\"\"\"You are a Python intelligence. You need to read the description below for the project and write the function(s) exactly mentioned in the description in Python.\n","\n","    The description of the project: <<{desc}>>\n","\n","    The function(s) you need to complete. Attention you need to complete the function(s) where written \"pass\":\n","    <<\n","    {stub_code}\n","    >>\n","\n","    Write only the required Python function(s) replacing the \"pass\" statement(s) with the appropriate code implementing the described functionality. Do not add any explanations, comments, additional functions, or any other content outside the specified function(s). Ensure that the code is executable and runnable as is.\n","\n","    # Output Format\n","\n","    Provide only valid Python code for the specified function(s), without any surrounding text or extra output.\n","\"\"\"\n","\n","    # ==================================================\n","    # Generate solution with Mistral\n","    # ==================================================\n","    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n","    output = model.generate(**inputs, max_new_tokens=500, temperature=0.0)\n","    code = tokenizer.decode(output[0], skip_special_tokens=True)\n","\n","    # extract python code block if present\n","    if \"```python\" in code:\n","        code = code.split(\"```python\")[1].split(\"```\")[0].strip()\n","\n","    # overwrite the stub file\n","    with open(stub_path, \"w\") as f:\n","        f.write(code)\n","\n","    # ==================================================\n","    # Run benchmark test\n","    # ==================================================\n","    ok, log = run_pytest(test_path)\n","    if ok:\n","        passed += 1\n","        print(f\"✅ {ex} — Passed\")\n","    else:\n","        print(f\"❌ {ex} — Failed\\n{log[:200]}\")\n","\n","    results_log.append({\"exercise\": ex, \"passed\": ok, \"log\": log[:400]})\n","\n","# ======================================================\n","# 5️⃣  Accuracy report\n","# ======================================================\n","if total > 0:\n","    acc = passed / total * 100\n","    print(f\"\\n🏁 Evaluation complete: {passed}/{total} passed → {acc:.2f}% accuracy\")\n","else:\n","    print(\"No exercises found to evaluate.\")\n","\n","# ======================================================\n","# 6️⃣  Save summary CSV\n","# ======================================================\n","df = pd.DataFrame(results_log)\n","df.to_csv(\"/content/drive/MyDrive/polyglot-benchmark/eval_summary.csv\", index=False)\n","print(\"📄 Results saved to: eval_summary.csv\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"collapsed":true,"id":"G7A4GCCbDToQ","executionInfo":{"status":"error","timestamp":1761143157327,"user_tz":-120,"elapsed":184712,"user":{"displayName":"hamidreza bahmanyar","userId":"02252184421162584539"}},"outputId":"1374dc46-1dfc-47c2-fd10-bd3ca7c4ca7e"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","/usr/local/lib/python3.12/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["❌ affine-cipher — Failed\n","F\n","=================================== FAILURES ===================================\n","___________________ AffineCipherTest.test_decode_a_sentence ____________________\n","\n","self = <affine_cipher_test.AffineCipherTest testMethod=test_decode_a_sentence>\n","\n","    def test_decode_a_sentence(self):\n",">       self.asse\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["❌ beer-song — Failed\n","F\n","=================================== FAILURES ===================================\n","_________________________ BeerSongTest.test_all_verses _________________________\n","\n","self = <beer_song_test.BeerSongTest testMethod=test_all_verses>\n","\n","    def test_all_verses(self):\n","        expected = [\n","            \"99 bo\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["❌ book-store — Failed\n","F\n","=================================== FAILURES ===================================\n","_ BookStoreTest.test_check_that_groups_of_four_are_created_properly_even_when_there_are_more_groups_of_three_than_groups_of_five _\n","\n","self = <book_store_test.BookStoreTest testMethod=test_check_that_groups_of_four_are_c\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["❌ bottle-song — Failed\n","F\n","=================================== FAILURES ===================================\n","________________________ BottleSongTest.test_all_verses ________________________\n","\n","self = <bottle_song_test.BottleSongTest testMethod=test_all_verses>\n","\n","    def test_all_verses(self):\n","        expected = [\n","            \"T\n","❌ bowling — Failed\n","F\n","=================================== FAILURES ===================================\n","___________ BowlingTest.test_a_roll_cannot_score_more_than_10_points ___________\n","\n","self = <bowling_test.BowlingTest testMethod=test_a_roll_cannot_score_more_than_10_points>\n","\n","    def test_a_roll_cannot_score_more_than_1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2171248385.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# Generate with Mistral\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0moutput_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0mgenerated_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m             \u001b[0;31m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2024\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2025\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2026\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2982\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2984\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msynced_gpus\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mthis_peer_finished\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/mistral/modeling_mistral.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1034\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/mistral/modeling_mistral.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    806\u001b[0m                 )\n\u001b[1;32m    807\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m    809\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/mistral/modeling_mistral.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_attention_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnew_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mpre_forward\u001b[0;34m(self, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m                 )\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         return send_to_device(args, self.execution_device), send_to_device(\n\u001b[0m\u001b[1;32m    365\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         return honor_type(\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msend_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_keys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mhonor_type\u001b[0;34m(obj, generator)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         return honor_type(\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msend_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_keys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         )\n\u001b[1;32m    178\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["import os\n","import subprocess\n","from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n","\n","# ===========================================================\n","# 2️⃣  Choose the exercise to test\n","# ===========================================================\n","exercise = \"/content/drive/MyDrive/polyglot-benchmark/python/exercises/practice\"\n","ex_path = f\"/content/drive/MyDrive/polyglot-benchmark/python/exercises/practice/{exercise}\"\n","\n","docs_path   = os.path.join(ex_path, \".docs\", \"instructions.md\")\n","append_path = os.path.join(ex_path, \".docs\", \"instructions.append.md\")\n","\n","stub_file = [f for f in os.listdir(ex_path)\n","             if f.endswith(\".py\") and not f.endswith(\"_test.py\")][0]\n","stub_path = os.path.join(ex_path, stub_file)\n","\n","test_file = [f for f in os.listdir(ex_path)\n","             if f.endswith(\"_test.py\")][0]\n","test_path = os.path.join(ex_path, test_file)\n","\n","# ===========================================================\n","# 3️⃣  Build the prompt\n","# ===========================================================\n","def shorten(text, max_chars=4000):\n","    text = text.strip()\n","    if len(text) > max_chars:\n","        text = text[:max_chars] + \"\\n\\n[...] (truncated)\"\n","    return text\n","\n","with open(docs_path) as f:\n","    desc = shorten(f.read())\n","append_txt = \"\"\n","if os.path.exists(append_path):\n","    with open(append_path) as f:\n","        append_txt = shorten(f.read(), 1000)\n","with open(stub_path) as f:\n","    stub_code = f.read()\n","\n","prompt = f\"\"\"You are an expert Python developer.\n","\n","### Problem Description\n","{desc}\n","\n","{\"### Additional Requirements\\n\" + append_txt if append_txt else \"\"}\n","\n","### Function Signatures\n","{stub_code}\n","\n","### Task\n","Implement these functions exactly as declared so that all tests in this exercise pass.\n","Do not add a main section or print statements. Return only Python code.\n","\"\"\"\n","\n","# ===========================================================\n","# 4️⃣  Generate model output (quiet, only code)\n","# ===========================================================\n","inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n","out_tokens = model.generate(**inputs, max_new_tokens=400, temperature=0.0)\n","code = tokenizer.decode(out_tokens[0], skip_special_tokens=True)\n","\n","# extract only the Python code block if present\n","if \"```python\" in code:\n","    code = code.split(\"```python\")[1].split(\"```\")[0].strip()\n","\n","# overwrite the stub file with generated code\n","with open(stub_path, \"w\") as f:\n","    f.write(code)\n","\n","# ===========================================================\n","# 5️⃣  Run pytest to evaluate correctness\n","# ===========================================================\n","try:\n","    res = subprocess.run(\n","        [\"pytest\", \"-q\", test_path, \"--disable-warnings\", \"--maxfail=1\"],\n","        capture_output=True, text=True, timeout=25, cwd=os.path.dirname(test_path)\n","    )\n","    passed = res.returncode == 0\n","except subprocess.TimeoutExpired:\n","    passed = False\n","\n","# ===========================================================\n","# 6️⃣  Report result\n","# ===========================================================\n","if passed:\n","    print(f\"✅ {exercise} — Passed all tests\")\n","    passed_count, total = 1, 1\n","else:\n","    print(f\"❌ {exercise} — Failed some tests\")\n","    passed_count, total = 0, 1\n","\n","accuracy = (passed_count / total) * 100\n","print(f\"\\n🏁 Accuracy: {accuracy:.2f}%\")\n"],"metadata":{"id":"Tj3ULSOeGMjT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5. Try to get the Mistral 7B llm model from OpenRouter."],"metadata":{"id":"FC9aWywdhxBG"}},{"cell_type":"code","source":["!pip install openai pytest tqdm\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gKJGd70ihwkw","executionInfo":{"status":"ok","timestamp":1761307846296,"user_tz":-120,"elapsed":33981,"user":{"displayName":"hamidreza bahmanyar","userId":"02252184421162584539"}},"outputId":"fee882ea-8050-4747-a259-2b321ecd9406"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n","Requirement already satisfied: pytest in /usr/local/lib/python3.12/dist-packages (8.4.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.1)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.10)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n","Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest) (2.3.0)\n","Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from pytest) (25.0)\n","Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest) (1.6.0)\n","Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from pytest) (2.19.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n"]}]},{"cell_type":"code","source":["    prompt = f\"\"\"Task: Complete the given Python code by implementing the logic as described in the provided documentation files.\n","      Ensure that you follow the instructions strictly, without renaming, removing, or creating any new functions, classes, or imports.\n","      Your goal is to replace the `pass` statement(s) or add the necessary logic inside the already defined function(s) inside the {code_template} file.\n","\n","      Output Format:\n","      - Provide the completed Python code in the same format as the provided incomplete code.\n","      - Ensure the code is syntactically correct and follows best practices.\n","\n","      Tone: Formal and technical, suitable for a programming audience.\n","\n","      Details Required:\n","      1. Primary Instructions: Follow the guidelines provided in the {instructions} file to understand the core functionality needed.\n","      2. Additional Requirements: Take into account any extra conditions specified in {append_text}, if applicable.\n","      3. Helpful Hints: Utilize hints from {hint_text} to guide your implementation, if available.\n","\n","\n","      Constraints:\n","      - Do not alter the structure of the code template.\n","      - Maintain the integrity of existing function definitions.\n","\n","      Example:\n","      If the incomplete code template is as follows:\n","      ```python\n","      def add_numbers(a, b):\n","      pass\n","      ```\n","      And the instructions state to return the sum of `a` and `b`, your output should be:\n","      ```python\n","      def add_numbers(a, b):\n","      return a + b\n","      ```\n","\n","      Instructions for Completion:\n","      - Read through the documentation files thoroughly.\n","      - Identify the required logic and incorporate it into the incomplete code.\n","      - Ensure your completed function behaves as intended when tested.\n","\n","      By following these guidelines, ensure that your response is accurate and fulfills the requirements outlined in the documentation provided."],"metadata":{"id":"L9sN3RVVWcGq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","os.environ[\"OPENAI_API_KEY\"] = \"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\"\n","\n"],"metadata":{"id":"KSGNMKd2iC81","executionInfo":{"status":"ok","timestamp":1761308075588,"user_tz":-120,"elapsed":6,"user":{"displayName":"hamidreza bahmanyar","userId":"02252184421162584539"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Checking the accuracy for the model Mistral-7B"],"metadata":{"id":"AM1P4nW-6hMG"}},{"cell_type":"code","source":["import re\n","import os\n","import subprocess\n","from openai import OpenAI\n","from tqdm import tqdm\n","import time\n","\n","# === CONFIG ===\n","bench_dir = \"/content/drive/MyDrive/polyglot-benchmark/python/exercises/practice\"\n","client = OpenAI(\n","    base_url=\"https://openrouter.ai/api/v1\",\n","    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",")\n","\n","model_name = \"mistralai/mistral-7b-instruct:free\"\n","temperature = 0.0\n","max_tokens = 700\n","\n","def clean_model_output(output: str) -> str:\n","    \"\"\"\n","    Remove markdown fences, explanations, and non-code text.\n","    Keep only valid Python code between ```python ... ```\n","    or the first block that looks like code.\n","    \"\"\"\n","    if not output:\n","        return \"\"\n","\n","    # Extract code between ```python ... ``` or ```\n","    code_blocks = re.findall(r\"```(?:python)?(.*?)```\", output, re.DOTALL)\n","    if code_blocks:\n","        cleaned = code_blocks[0].strip()\n","    else:\n","        # Fallback: remove lines that clearly aren’t code\n","        cleaned = \"\\n\".join(\n","            line for line in output.splitlines()\n","            if not line.strip().startswith((\"```\", \"#\", \"Here\", \"The description\"))\n","        )\n","    return cleaned.strip()\n","\n","# === UTILITY FUNCTIONS ===\n","def run_pytest(test_path):\n","    \"\"\"Run pytest on the given test file.\"\"\"\n","    try:\n","        result = subprocess.run(\n","            [\"pytest\", \"-q\", test_path],\n","            capture_output=True,\n","            text=True,\n","            timeout=20\n","        )\n","        return result.returncode == 0\n","    except Exception as e:\n","        print(f\"Error running tests for {test_path}: {e}\")\n","        return False\n","\n","\n","def generate_code(prompt):\n","    \"\"\"Generate code from Mistral 7B using OpenRouter.\"\"\"\n","    try:\n","        response = client.chat.completions.create(\n","            model=model_name,\n","            messages=[\n","                {\"role\": \"system\", \"content\": \"You are an expert Python developer.\"},\n","                {\"role\": \"user\", \"content\": prompt},\n","            ],\n","            temperature=temperature,\n","            max_tokens=max_tokens,\n","        )\n","        return response.choices[0].message.content.strip()\n","    except Exception as e:\n","        print(f\"Generation failed: {e}\")\n","        return \"\"\n","\n","\n","# === MAIN EVALUATION LOOP ===\n","exercise_dirs = [\n","    os.path.join(bench_dir, d) for d in os.listdir(bench_dir)\n","    if os.path.isdir(os.path.join(bench_dir, d))\n","]\n","\n","passed, total = 0, 0\n","\n","for ex_dir in tqdm(exercise_dirs, desc=\"Evaluating exercises\"):\n","    instr_path = os.path.join(ex_dir, \".docs\", \"instructions.md\")\n","    py_file = next((f for f in os.listdir(ex_dir) if f.endswith(\".py\") and \"_test\" not in f), None)\n","    test_file = next((f for f in os.listdir(ex_dir) if f.endswith(\"_test.py\")), None)\n","    append_path = os.path.join(ex_dir, \".docs\", \"instructions.append.md\")\n","    hint_path = os.path.join(ex_dir, \".docs\", \"hint.md\")\n","    ex_name = os.path.basename(ex_dir)\n","\n","    if not instr_path or not py_file or not test_file:\n","        continue\n","\n","    total += 1\n","    with open(instr_path, \"r\", encoding=\"utf-8\") as f:\n","      instructions = f.read()\n","\n","    py_path = os.path.join(ex_dir, py_file)\n","    with open(py_path, \"r\", encoding=\"utf-8\") as f:\n","      code_template = f.read()\n","\n","    if os.path.exists(append_path):\n","      with open(append_path, \"r\", encoding=\"utf-8\") as f:\n","          append_text = f.read()\n","\n","\n","\n","    prompt = f\"\"\"\n","      You are a Python intelligence. You need to read the description below for the project and write the function(s) exactly mentioned in the description in Python.\n","\n","      The description of the project: <<{instructions}>>\n","\n","      {\"### Additional Requirements\\n\" + append_text if append_text else \"\"}\n","\n","      The function(s) you need to complete. Attention you need to complete the function(s) where written <<pass>>:\n","      <<\n","      {code_template}\n","      >>\n","\n","      Write only the required Python function(s) replacing the <<pass>> statement(s) with the appropriate code implementing the described functionality.\n","      Do not add any explanations, comments, additional functions, or any other content outside the specified function(s). Ensure that the code is executable and runnable as is.\n","\n","      ### Output Format\n","\n","      Provide only valid Python code for the specified function(s), without any surrounding text or extra output.\n","\n","    \"\"\"\n","    prompt_2 = f\"\"\"\n","      Here is the incomplete Python code that you must complete:\n","      ```python\n","      {code_template}\n","      Now read the following documentation carefully to understand what the code must do:\n","\n","      Primary Instructions:\n","      {instructions}\n","\n","      Additional Requirements:\n","      {append_text}\n","\n","      Hints:\n","      {hint_text}\n","\n","      Task:\n","      Complete only the existing function(s).\n","\n","      Replace pass with correct logic.\n","\n","      Do not create new functions, imports, or classes.\n","\n","      Output only valid Python code.\n","      \"\"\"\n","\n","    prompt_2 = f\"\"\"Task: Complete the given Python code by implementing the logic as described in the provided documentation files.\n","      Ensure that you follow the instructions strictly, without renaming, removing, or creating any new functions, classes, or imports.\n","      Your goal is to replace the `pass` statement(s) or add the necessary logic inside the already defined function(s) inside the {code_template} file.\n","\n","      Output Format:\n","      - Provide the completed Python code in the same format as the provided incomplete code.\n","      - Ensure the code is syntactically correct and follows best practices.\n","\n","      Tone: Formal and technical, suitable for a programming audience.\n","\n","      Details Required:\n","      1. Primary Instructions: Follow the guidelines provided in the {instructions} file to understand the core functionality needed.\n","      2. Additional Requirements: Take into account any extra conditions specified in {append_text}, if applicable.\n","      3. Helpful Hints: Utilize hints from {hint_text} to guide your implementation, if available.\n","\n","\n","      Constraints:\n","      - Do not alter the structure of the code template.\n","      - Maintain the integrity of existing function definitions.\n","\n","      Example:\n","      If the incomplete code template is as follows:\n","      ```python\n","      def add_numbers(a, b):\n","      pass\n","      ```\n","      And the instructions state to return the sum of `a` and `b`, your output should be:\n","      ```python\n","      def add_numbers(a, b):\n","      return a + b\n","      ```\n","\n","      Instructions for Completion:\n","      - Read through the documentation files thoroughly.\n","      - Identify the required logic and incorporate it into the incomplete code.\n","      - Ensure your completed function behaves as intended when tested.\n","\n","      By following these guidelines, ensure that your response is accurate and fulfills the requirements outlined in the documentation provided.\n","      \"\"\"\n","\n","    # Generate code and overwrite the exercise .py file\n","    py_path = os.path.join(ex_dir, py_file)\n","    code = generate_code(prompt_2)\n","    code = clean_model_output(code)\n","    time.sleep(5)\n","\n","    if not code:\n","        print(f\"No code generated for {ex_name}\")\n","        continue\n","\n","    with open(py_path, \"w\", encoding=\"utf-8\") as f:\n","        f.write(code)\n","\n","    # Run the associated test\n","    test_path = os.path.join(ex_dir, test_file)\n","    passed_flag = run_pytest(test_path)\n","    if passed_flag:\n","        passed += 1\n","        print(f\"Passed: {ex_name}\")\n","    else:\n","        print(f\"Failed: {ex_name}\")\n","\n","accuracy = (passed / total * 100) if total else 0\n","print(f\"\\nAccuracy: {accuracy:.2f}%  ({passed}/{total} exercises passed)\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":495},"id":"m_62RVJ3i2Qj","executionInfo":{"status":"error","timestamp":1761313948285,"user_tz":-120,"elapsed":61519,"user":{"displayName":"hamidreza bahmanyar","userId":"02252184421162584539"}},"outputId":"1379f7ac-1c6e-4114-b7d4-9a9d6fb955d4"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":["Evaluating exercises:   3%|▎         | 1/34 [00:05<03:15,  5.92s/it]"]},{"output_type":"stream","name":"stdout","text":["No code generated for affine-cipher\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:   6%|▌         | 2/34 [00:11<03:05,  5.81s/it]"]},{"output_type":"stream","name":"stdout","text":["No code generated for beer-song\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:   9%|▉         | 3/34 [00:20<03:37,  7.01s/it]"]},{"output_type":"stream","name":"stdout","text":["No code generated for book-store\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  12%|█▏        | 4/34 [00:25<03:16,  6.54s/it]"]},{"output_type":"stream","name":"stdout","text":["No code generated for bottle-song\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  15%|█▍        | 5/34 [00:53<06:53, 14.25s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: bowling\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  18%|█▊        | 6/34 [00:59<05:20, 11.43s/it]"]},{"output_type":"stream","name":"stdout","text":["No code generated for connect\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  18%|█▊        | 6/34 [01:01<04:45, 10.18s/it]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3298415120.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;31m# Generate code and overwrite the exercise .py file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0mpy_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpy_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m     \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m     \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_model_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-3298415120.py\u001b[0m in \u001b[0;36mgenerate_code\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;34m\"\"\"Generate code from Mistral 7B using OpenRouter.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         response = client.chat.completions.create(\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             messages=[\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m   1146\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             body=maybe_transform(\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         )\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m     def patch(\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m    980\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m                 response = self._client.send(\n\u001b[0m\u001b[1;32m    983\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m                     \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stream_response_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m     def _send_handling_auth(\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_models.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \"\"\"\n\u001b[1;32m    880\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_content\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_models.py\u001b[0m in \u001b[0;36miter_bytes\u001b[0;34m(self, chunk_size)\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mchunker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mByteChunker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mraw_bytes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m                     \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_models.py\u001b[0m in \u001b[0;36miter_raw\u001b[0;34m(self, chunk_size)\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mraw_stream_bytes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_bytes_downloaded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_stream_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_stream_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_httpcore_stream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mShieldCancellation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"receive_response_body\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_response_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_response_body\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEED_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 data = self._network_stream.read(\n\u001b[0m\u001b[1;32m    218\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_NUM_BYTES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1230\u001b[0m                     \u001b[0;34m\"non-zero flags not allowed in calls to recv() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m                     self.__class__)\n\u001b[0;32m-> 1232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1233\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1103\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["!cat \"/content/drive/MyDrive/polyglot-benchmark/python/exercises/practice/transpose/transpose.py\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9tZ31eZxmaJh","executionInfo":{"status":"ok","timestamp":1761311536082,"user_tz":-120,"elapsed":129,"user":{"displayName":"hamidreza bahmanyar","userId":"02252184421162584539"}},"outputId":"5855b4dc-abc6-49d1-cdfb-d151560c4a7b"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["<s>def transpose(text):\n","    if not text:\n","        return \"\"\n","\n","    rows = text.split('\\n')\n","    max_length = max(len(row) for row in rows)\n","    padded_rows = [row.ljust(max_length) for row in rows]\n","\n","    transposed = []\n","    for col in range(max_length):\n","        new_row = ''.join([padded_rows[row][col] for row in range(len(padded_rows))])\n","        transposed.append(new_row)\n","\n","    return '\\n'.join(transposed)\n","      >"]}]},{"cell_type":"markdown","source":["## Checking the accuracy for the model Llama 3.2-3B"],"metadata":{"id":"PTc2lXML6Zu1"}},{"cell_type":"code","source":["import re\n","import os\n","import subprocess\n","from openai import OpenAI\n","from tqdm import tqdm\n","import time\n","\n","# === CONFIG ===\n","bench_dir = \"/content/drive/MyDrive/polyglot-benchmark/python/exercises/practice\"\n","client = OpenAI(\n","  base_url=\"https://openrouter.ai/api/v1\",\n","  api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",")\n","\n","model_name = \"meta-llama/llama-3.2-3b-instruct:free\"\n","temperature = 0.0\n","max_tokens = 1000\n","\n","def clean_model_output(output: str) -> str:\n","  \"\"\"\n","  Remove markdown fences, explanations, and non-code text.\n","  Keep only valid Python code between ```python ... ```\n","  or the first block that looks like code.\n","  \"\"\"\n","  if not output:\n","      return \"\"\n","\n","  # Extract code between ```python ... ``` or ```\n","  code_blocks = re.findall(r\"```(?:python)?(.*?)```\", output, re.DOTALL)\n","  if code_blocks:\n","      cleaned = code_blocks[0].strip()\n","  else:\n","      # Fallback: remove lines that clearly aren’t code\n","      cleaned = \"\\n\".join(\n","          line for line in output.splitlines()\n","          if not line.strip().startswith((\"```\", \"#\", \"Here\", \"The description\"))\n","      )\n","  return cleaned.strip()\n","\n","# === UTILITY FUNCTIONS ===\n","def run_pytest(test_path):\n","  \"\"\"Run pytest on the given test file.\"\"\"\n","  try:\n","      result = subprocess.run(\n","          [\"pytest\", \"-q\", test_path],\n","          capture_output=True,\n","          text=True,\n","          timeout=20\n","      )\n","      return result.returncode == 0\n","  except Exception as e:\n","      print(f\"Error running tests for {test_path}: {e}\")\n","      return False\n","\n","\n","def generate_code(prompt):\n","  \"\"\"Generate code from Mistral 7B using OpenRouter.\"\"\"\n","  try:\n","      response = client.chat.completions.create(\n","          model=model_name,\n","          messages=[\n","              {\"role\": \"system\", \"content\": \"You are an expert Python developer.\"},\n","              {\"role\": \"user\", \"content\": prompt},\n","          ],\n","          temperature=temperature,\n","          max_tokens=max_tokens,\n","      )\n","      return response.choices[0].message.content.strip()\n","  except Exception as e:\n","      print(f\"Generation failed: {e}\")\n","      return \"\"\n","\n","\n","# === MAIN EVALUATION LOOP ===\n","exercise_dirs = [\n","  os.path.join(bench_dir, d) for d in os.listdir(bench_dir)\n","  if os.path.isdir(os.path.join(bench_dir, d))\n","]\n","\n","passed, total = 0, 0\n","\n","for ex_dir in tqdm(exercise_dirs, desc=\"Evaluating exercises\"):\n","  instr_path = os.path.join(ex_dir, \".docs\", \"instructions.md\")\n","  py_file = next((f for f in os.listdir(ex_dir) if f.endswith(\".py\") and \"_test\" not in f), None)\n","  test_file = next((f for f in os.listdir(ex_dir) if f.endswith(\"_test.py\")), None)\n","  append_path = os.path.join(ex_dir, \".docs\", \"instructions.append.md\")\n","  hint_path = os.path.join(ex_dir, \".docs\", \"hint.md\")\n","  ex_name = os.path.basename(ex_dir)\n","\n","  if not instr_path or not py_file or not test_file:\n","      continue\n","\n","  total += 1\n","  with open(instr_path, \"r\", encoding=\"utf-8\") as f:\n","    instructions = f.read()\n","\n","  py_path = os.path.join(ex_dir, py_file)\n","  with open(py_path, \"r\", encoding=\"utf-8\") as f:\n","    code_template = f.read()\n","\n","  if os.path.exists(append_path):\n","    with open(append_path, \"r\", encoding=\"utf-8\") as f:\n","        append_text = f.read()\n","\n","\n","\n","  prompt = f\"\"\"\n","    You are a Python intelligence. You need to read the description below for the project and write the function(s) exactly mentioned in the description in Python.\n","\n","    The description of the project: <<{instructions}>>\n","\n","    {\"### Additional Requirements\\n\" + append_text if append_text else \"\"}\n","\n","    The function(s) you need to complete. Attention you need to complete the function(s) where written <<pass>>:\n","    <<\n","    {code_template}\n","    >>\n","\n","    Write only the required Python function(s) replacing the <<pass>> statement(s) with the appropriate code implementing the described functionality.\n","    Do not add any explanations, comments, additional functions, or any other content outside the specified function(s). Ensure that the code is executable and runnable as is.\n","\n","    ### Output Format\n","\n","    Provide only valid Python code for the specified function(s), without any surrounding text or extra output.\n","\n","  \"\"\"\n","\n","  prompt_2 = f\"\"\"Task: Complete the given Python code by implementing the logic as described in the provided documentation files.\n","      Ensure that you follow the instructions strictly, without renaming, removing, or creating any new functions, classes, or imports.\n","      Your goal is to replace the `pass` statement(s) or add the necessary logic inside the already defined function(s) inside the {code_template} file.\n","\n","      Output Format:\n","      - Provide the completed Python code in the same format as the provided incomplete code.\n","      - Ensure the code is syntactically correct and follows best practices.\n","\n","      Tone: Formal and technical, suitable for a programming audience.\n","\n","      Details Required:\n","      1. Primary Instructions: Follow the guidelines provided in the {instructions} file to understand the core functionality needed.\n","      2. Additional Requirements: Take into account any extra conditions specified in {append_text}, if applicable.\n","      3. Helpful Hints: Utilize hints from {hint_text} to guide your implementation, if available.\n","\n","\n","      Constraints:\n","      - Do not alter the structure of the code template.\n","      - Maintain the integrity of existing function definitions.\n","\n","      Example:\n","      If the incomplete code template is as follows:\n","      ```python\n","      def add_numbers(a, b):\n","      pass\n","      ```\n","      And the instructions state to return the sum of `a` and `b`, your output should be:\n","      ```python\n","      def add_numbers(a, b):\n","      return a + b\n","      ```\n","\n","      Instructions for Completion:\n","      - Read through the documentation files thoroughly.\n","      - Identify the required logic and incorporate it into the incomplete code.\n","      - Ensure your completed function behaves as intended when tested.\n","\n","      By following these guidelines, ensure that your response is accurate and fulfills the requirements outlined in the documentation provided.\n","  \"\"\"\n","  # Generate code and overwrite the exercise .py file\n","  py_path = os.path.join(ex_dir, py_file)\n","  code = generate_code(prompt_2)\n","  code = clean_model_output(code)\n","\n","  if not code:\n","      print(f\"No code generated for {ex_name}\")\n","      continue\n","\n","  with open(py_path, \"w\", encoding=\"utf-8\") as f:\n","      f.write(code)\n","\n","  # Run the associated test\n","  test_path = os.path.join(ex_dir, test_file)\n","  passed_flag = run_pytest(test_path)\n","  if passed_flag:\n","      passed += 1\n","      print(f\"Passed: {ex_name}\")\n","  else:\n","      print(f\"Failed: {ex_name}\")\n","\n","accuracy = (passed / total * 100) if total else 0\n","print(f\"\\nAccuracy: {accuracy:.2f}%  ({passed}/{total} exercises passed)\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3sYuhxO5N_2G","executionInfo":{"status":"ok","timestamp":1761314575128,"user_tz":-120,"elapsed":561948,"user":{"displayName":"hamidreza bahmanyar","userId":"02252184421162584539"}},"outputId":"9ff086e5-b03e-489f-f48e-8524e759b828"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["Evaluating exercises:   3%|▎         | 1/34 [00:28<15:32, 28.26s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: affine-cipher\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:   6%|▌         | 2/34 [00:39<09:50, 18.45s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: beer-song\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:   9%|▉         | 3/34 [01:10<12:22, 23.96s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: book-store\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  12%|█▏        | 4/34 [01:19<09:08, 18.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: bottle-song\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  15%|█▍        | 5/34 [01:57<12:15, 25.37s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: bowling\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  18%|█▊        | 6/34 [02:13<10:20, 22.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: connect\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  21%|██        | 7/34 [02:16<07:03, 15.68s/it]"]},{"output_type":"stream","name":"stdout","text":["Generation failed: Error code: 429 - {'error': {'message': 'Provider returned error', 'code': 429, 'metadata': {'raw': 'meta-llama/llama-3.2-3b-instruct:free is temporarily rate-limited upstream. Please retry shortly, or add your own key to accumulate your rate limits: https://openrouter.ai/settings/integrations', 'provider_name': 'Venice'}}, 'user_id': 'user_34T64NRW09AE1IOhHpOs4qHu0F8'}\n","No code generated for dominoes\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  24%|██▎       | 8/34 [02:18<04:56, 11.40s/it]"]},{"output_type":"stream","name":"stdout","text":["Generation failed: Error code: 429 - {'error': {'message': 'Provider returned error', 'code': 429, 'metadata': {'raw': 'meta-llama/llama-3.2-3b-instruct:free is temporarily rate-limited upstream. Please retry shortly, or add your own key to accumulate your rate limits: https://openrouter.ai/settings/integrations', 'provider_name': 'Venice'}}, 'user_id': 'user_34T64NRW09AE1IOhHpOs4qHu0F8'}\n","No code generated for dot-dsl\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  26%|██▋       | 9/34 [02:20<03:33,  8.53s/it]"]},{"output_type":"stream","name":"stdout","text":["Generation failed: Error code: 429 - {'error': {'message': 'Provider returned error', 'code': 429, 'metadata': {'raw': 'meta-llama/llama-3.2-3b-instruct:free is temporarily rate-limited upstream. Please retry shortly, or add your own key to accumulate your rate limits: https://openrouter.ai/settings/integrations', 'provider_name': 'Venice'}}, 'user_id': 'user_34T64NRW09AE1IOhHpOs4qHu0F8'}\n","No code generated for food-chain\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  29%|██▉       | 10/34 [02:22<02:37,  6.54s/it]"]},{"output_type":"stream","name":"stdout","text":["Generation failed: Error code: 429 - {'error': {'message': 'Provider returned error', 'code': 429, 'metadata': {'raw': 'meta-llama/llama-3.2-3b-instruct:free is temporarily rate-limited upstream. Please retry shortly, or add your own key to accumulate your rate limits: https://openrouter.ai/settings/integrations', 'provider_name': 'Venice'}}, 'user_id': 'user_34T64NRW09AE1IOhHpOs4qHu0F8'}\n","No code generated for forth\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  32%|███▏      | 11/34 [02:25<02:01,  5.26s/it]"]},{"output_type":"stream","name":"stdout","text":["Generation failed: Error code: 429 - {'error': {'message': 'Provider returned error', 'code': 429, 'metadata': {'raw': 'meta-llama/llama-3.2-3b-instruct:free is temporarily rate-limited upstream. Please retry shortly, or add your own key to accumulate your rate limits: https://openrouter.ai/settings/integrations', 'provider_name': 'Venice'}}, 'user_id': 'user_34T64NRW09AE1IOhHpOs4qHu0F8'}\n","No code generated for go-counting\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  35%|███▌      | 12/34 [02:43<03:22,  9.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: grade-school\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  38%|███▊      | 13/34 [03:01<04:12, 12.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: grep\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  41%|████      | 14/34 [03:12<03:51, 11.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: hangman\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  44%|████▍     | 15/34 [03:27<04:02, 12.78s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: list-ops\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  47%|████▋     | 16/34 [03:44<04:09, 13.86s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: paasio\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  50%|█████     | 17/34 [04:01<04:11, 14.82s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: phone-number\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  53%|█████▎    | 18/34 [04:10<03:30, 13.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: pig-latin\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  56%|█████▌    | 19/34 [04:28<03:40, 14.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: poker\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  59%|█████▉    | 20/34 [04:44<03:31, 15.12s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: pov\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  62%|██████▏   | 21/34 [04:51<02:43, 12.55s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: proverb\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  65%|██████▍   | 22/34 [05:09<02:49, 14.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: react\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  68%|██████▊   | 23/34 [05:44<03:45, 20.53s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: rest-api\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  71%|███████   | 24/34 [06:15<03:56, 23.68s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: robot-name\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  74%|███████▎  | 25/34 [06:37<03:27, 23.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: scale-generator\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  76%|███████▋  | 26/34 [06:54<02:50, 21.34s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: sgf-parsing\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  79%|███████▉  | 27/34 [07:21<02:41, 23.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: simple-linked-list\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  82%|████████▏ | 28/34 [07:24<01:40, 16.82s/it]"]},{"output_type":"stream","name":"stdout","text":["Generation failed: Error code: 429 - {'error': {'message': 'Provider returned error', 'code': 429, 'metadata': {'raw': 'meta-llama/llama-3.2-3b-instruct:free is temporarily rate-limited upstream. Please retry shortly, or add your own key to accumulate your rate limits: https://openrouter.ai/settings/integrations', 'provider_name': 'Venice'}}, 'user_id': 'user_34T64NRW09AE1IOhHpOs4qHu0F8'}\n","No code generated for transpose\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  85%|████████▌ | 29/34 [07:26<01:02, 12.41s/it]"]},{"output_type":"stream","name":"stdout","text":["Generation failed: Error code: 429 - {'error': {'message': 'Provider returned error', 'code': 429, 'metadata': {'raw': 'meta-llama/llama-3.2-3b-instruct:free is temporarily rate-limited upstream. Please retry shortly, or add your own key to accumulate your rate limits: https://openrouter.ai/settings/integrations', 'provider_name': 'Venice'}}, 'user_id': 'user_34T64NRW09AE1IOhHpOs4qHu0F8'}\n","No code generated for tree-building\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  88%|████████▊ | 30/34 [07:53<01:07, 16.77s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: two-bucket\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  91%|█████████ | 31/34 [08:10<00:50, 16.98s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: variable-length-quantity\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  94%|█████████▍| 32/34 [08:22<00:30, 15.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: wordy\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  97%|█████████▋| 33/34 [09:01<00:22, 22.53s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: zebra-puzzle\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating exercises: 100%|██████████| 34/34 [09:21<00:00, 16.52s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: zipper\n","\n","Accuracy: 0.00%  (0/34 exercises passed)\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["!cat \"/content/drive/MyDrive/polyglot-benchmark/python/exercises/practice/wordy/wordy.py\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wjsCfpRdbSaG","executionInfo":{"status":"ok","timestamp":1761314622644,"user_tz":-120,"elapsed":163,"user":{"displayName":"hamidreza bahmanyar","userId":"02252184421162584539"}},"outputId":"5bc5af03-3fab-48b2-fa66-e396db4750cd"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["import re\n","\n","def answer(question):\n","    # Check if the question is not a math question\n","    if not re.match(r'^What is [-\\d+\\s]*\\?$', question):\n","        raise ValueError(\"syntax error\")\n","\n","    # Extract the math expression part\n","    expression = question[8:-1].strip()\n","\n","    # Split the expression into tokens\n","    tokens = re.findall(r'[\\d-]+|[+\\-*/]', expression)\n","\n","    # Check for unsupported operations\n","    for token in tokens:\n","        if token not in ['+', '-', '*', '/']:\n","            raise ValueError(\"unknown operation\")\n","\n","    # Check for invalid syntax\n","    if len(tokens) == 0 or len(tokens) % 2 != 1:\n","        raise ValueError(\"syntax error\")\n","\n","    # Initialize the result with the first number\n","    result = int(tokens[0])\n","\n","    # Iterate through the remaining tokens and perform operations\n","    for i in range(1, len(tokens), 2):\n","        operator = tokens[i]\n","        next_num = int(tokens[i+1])\n","\n","        if operator == '+':\n","            result += next_num\n","        elif operator == '-':\n","            result -= next_num\n","        elif operator == '*':\n","            result *= next_num\n","        elif operator == '/':\n","            if next_num == 0:\n","                raise ValueError(\"syntax error\")\n","            result //= next_num\n","\n","    return result"]}]},{"cell_type":"code","source":["!cat \"/content/drive/MyDrive/polyglot-benchmark/python/exercises/practice/transpose/transpose.py\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GigVdtRpenSb","executionInfo":{"status":"ok","timestamp":1761314638213,"user_tz":-120,"elapsed":127,"user":{"displayName":"hamidreza bahmanyar","userId":"02252184421162584539"}},"outputId":"eb948e68-fee0-4a00-ba6d-160945bef529"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["class Node:\n","    def __init__(self, data=None):\n","        self.data = data\n","        self.next = None\n","\n","class LinkedList:\n","    def __init__(self):\n","        self.head = None\n","\n","    def append(self, data):\n","        if not self.head:\n","            self.head = Node(data)\n","        else:\n","            current = self.head\n","            while current.next:\n","                current = current.next\n","            current.next = Node(data)\n","\n","    def __len__(self):\n","        current = self.head\n","        count = 0\n","        while current:\n","            count += 1\n","            current = current.next\n","        return count\n","\n","    def __iter__(self):\n","        current = self.head\n","        while current:\n","            yield current.data\n","            current = current.next\n","\n","class EmptyListException(Exception):\n","    \"\"\"Exception raised when the linked list is empty.\"\"\"\n","    def __init__(self, message):\n","        self.message = message\n","\n","def transpose(text):\n","    if not text:\n","        raise EmptyListException(\"The list is empty.\")\n","\n","    rows = text.split('\\n')\n","    max_length = max(len(row) for row in rows)\n","    padded_rows = [row.ljust(max_length) for row in rows]\n","\n","    linked_list = LinkedList()\n","    for row in padded_rows:\n","        linked_list.append(row)\n","\n","    transposed = []\n","    for col in range(max_length):\n","        new_row = ''.join([linked_list.data for node in linked_list if node.data])\n","        transposed.append(new_row)\n","\n","    return '\\n'.join(transposed)"]}]},{"cell_type":"markdown","source":["## Checking the accuracy for the model Devstral"],"metadata":{"id":"CAib-aLJ6N8c"}},{"cell_type":"code","source":["import re\n","import os\n","import subprocess\n","from openai import OpenAI\n","from tqdm import tqdm\n","import time\n","\n","# === CONFIG ===\n","bench_dir = \"/content/drive/MyDrive/polyglot-benchmark/python/exercises/practice\"\n","client = OpenAI(\n","  base_url=\"https://openrouter.ai/api/v1\",\n","  api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",")\n","\n","model_name = \"mistralai/devstral-small-2505:free\"\n","temperature = 0.0\n","max_tokens = 1000\n","\n","def clean_model_output(output: str) -> str:\n","  \"\"\"\n","  Remove markdown fences, explanations, and non-code text.\n","  Keep only valid Python code between ```python ... ```\n","  or the first block that looks like code.\n","  \"\"\"\n","  if not output:\n","      return \"\"\n","\n","  # Extract code between ```python ... ``` or ```\n","  code_blocks = re.findall(r\"```(?:python)?(.*?)```\", output, re.DOTALL)\n","  if code_blocks:\n","      cleaned = code_blocks[0].strip()\n","  else:\n","      # Fallback: remove lines that clearly aren’t code\n","      cleaned = \"\\n\".join(\n","          line for line in output.splitlines()\n","          if not line.strip().startswith((\"```\", \"#\", \"Here\", \"The description\"))\n","      )\n","  return cleaned.strip()\n","\n","# === UTILITY FUNCTIONS ===\n","def run_pytest(test_path):\n","  \"\"\"Run pytest on the given test file.\"\"\"\n","  try:\n","      result = subprocess.run(\n","          [\"pytest\", \"-q\", test_path],\n","          capture_output=True,\n","          text=True,\n","          timeout=20\n","      )\n","      return result.returncode == 0\n","  except Exception as e:\n","      print(f\"Error running tests for {test_path}: {e}\")\n","      return False\n","\n","\n","def generate_code(prompt):\n","  try:\n","      response = client.chat.completions.create(\n","          model=model_name,\n","          messages=[\n","              {\"role\": \"system\", \"content\": \"You are an expert Python developer.\"},\n","              {\"role\": \"user\", \"content\": prompt},\n","          ],\n","          temperature=temperature,\n","          max_tokens=max_tokens,\n","      )\n","      return response.choices[0].message.content.strip()\n","  except Exception as e:\n","      print(f\"Generation failed: {e}\")\n","      return \"\"\n","\n","\n","# === MAIN EVALUATION LOOP ===\n","exercise_dirs = [\n","  os.path.join(bench_dir, d) for d in os.listdir(bench_dir)\n","  if os.path.isdir(os.path.join(bench_dir, d))\n","]\n","\n","passed, total = 0, 0\n","\n","for ex_dir in tqdm(exercise_dirs, desc=\"Evaluating exercises\"):\n","  instr_path = os.path.join(ex_dir, \".docs\", \"instructions.md\")\n","  py_file = next((f for f in os.listdir(ex_dir) if f.endswith(\".py\") and \"_test\" not in f), None)\n","  test_file = next((f for f in os.listdir(ex_dir) if f.endswith(\"_test.py\")), None)\n","  append_path = os.path.join(ex_dir, \".docs\", \"instructions.append.md\")\n","  hint_path = os.path.join(ex_dir, \".docs\", \"hint.md\")\n","  ex_name = os.path.basename(ex_dir)\n","\n","  if not instr_path or not py_file or not test_file:\n","      continue\n","\n","  total += 1\n","  with open(instr_path, \"r\", encoding=\"utf-8\") as f:\n","    instructions = f.read()\n","\n","  py_path = os.path.join(ex_dir, py_file)\n","  with open(py_path, \"r\", encoding=\"utf-8\") as f:\n","    code_template = f.read()\n","\n","  if os.path.exists(append_path):\n","    with open(append_path, \"r\", encoding=\"utf-8\") as f:\n","        append_text = f.read()\n","\n","  test_path = os.path.join(ex_dir, test_file)\n","  with open(test_path, \"r\", encoding=\"utf-8\") as f:\n","    test_content = f.read()\n","\n","  prompt = f\"\"\"\n","    You are a Python intelligence. You need to read the description below for the project and write the function(s) exactly mentioned in the description in Python.\n","\n","    The description of the project: <<{instructions}>>\n","\n","    {\"### Additional Requirements\\n\" + append_text if append_text else \"\"}\n","\n","    The function(s) you need to complete. Attention you need to complete the function(s) where written <<pass>>:\n","    <<\n","    {code_template}\n","    >>\n","\n","    Write only the required Python function(s) replacing the <<pass>> statement(s) with the appropriate code implementing the described functionality.\n","    Do not add any explanations, comments, additional functions, or any other content outside the specified function(s). Ensure that the code is executable and runnable as is.\n","\n","    ### Output Format\n","\n","    Provide only valid Python code for the specified function(s), without any surrounding text or extra output.\n","\n","  \"\"\"\n","\n","  prompt_2 = f\"\"\"Task: Complete the given Python code by implementing the logic as described in the provided documentation files.\n","      Ensure that you follow the instructions strictly, without renaming, removing, or creating any new functions, classes, or imports.\n","      Your goal is to replace the `pass` statement(s) or add the necessary logic inside the already defined function(s) inside the {code_template} file.\n","\n","      Output Format:\n","      - Provide the completed Python code in the same format as the provided incomplete code.\n","      - Ensure the code is syntactically correct and follows best practices.\n","\n","      Tone: Formal and technical, suitable for a programming audience.\n","\n","      Details Required:\n","      1. Primary Instructions: Follow the guidelines provided in the {instructions} file to understand the core functionality needed.\n","      2. Additional Requirements: Take into account any extra conditions specified in {append_text}, if applicable.\n","      3. Helpful Hints: Utilize hints from {hint_text} to guide your implementation, if available.\n","      4. Test File: Review the {test_content} file to validate the functionality of your code. If your code passes the tests, indicate success; if it fails, attempt to improve the code to meet the requirements and pass the tests.\n","\n","\n","      Constraints:\n","      - Do not alter the structure of the code template.\n","      - Maintain the integrity of existing function definitions.\n","\n","      Example:\n","      If the incomplete code template is as follows:\n","      ```python\n","      def add_numbers(a, b):\n","      pass\n","      ```\n","      And the instructions state to return the sum of `a` and `b`, your output should be:\n","      ```python\n","      def add_numbers(a, b):\n","      return a + b\n","      ```\n","\n","      Instructions for Completion:\n","      - Read through the documentation files thoroughly.\n","      - Identify the required logic and incorporate it into the incomplete code.\n","      - Ensure your completed function behaves as intended when tested.\n","\n","      By following these guidelines, ensure that your response is accurate and fulfills the requirements outlined in the documentation provided.\n","      \"\"\"\n","\n","  # Generate code and overwrite the exercise .py file\n","  py_path = os.path.join(ex_dir, py_file)\n","  code = generate_code(prompt_2)\n","  code = clean_model_output(code)\n","  time.sleep(5)\n","\n","  if not code:\n","      print(f\"No code generated for {ex_name}\")\n","      continue\n","\n","  with open(py_path, \"w\", encoding=\"utf-8\") as f:\n","      f.write(code)\n","\n","  # === NEW: also save each generated code into results folder ===\n","  results_dir = \"/content/drive/MyDrive/devstral\"\n","  os.makedirs(results_dir, exist_ok=True)  # create folder if it doesn't exist\n","  result_file_path = os.path.join(results_dir, f\"{ex_name}.py\")\n","\n","  with open(result_file_path, \"w\", encoding=\"utf-8\") as rf:\n","      rf.write(code)\n","\n","  # Run the associated test\n","  test_path = os.path.join(ex_dir, test_file)\n","  passed_flag = run_pytest(test_path)\n","  if passed_flag:\n","      passed += 1\n","      print(f\"Passed: {ex_name}\")\n","  else:\n","      print(f\"Failed: {ex_name}\")\n","\n","accuracy = (passed / total * 100) if total else 0\n","print(f\"\\nAccuracy: {accuracy:.2f}%  ({passed}/{total} exercises passed)\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oZahzTgCiIf_","executionInfo":{"status":"ok","timestamp":1761316146063,"user_tz":-120,"elapsed":487419,"user":{"displayName":"hamidreza bahmanyar","userId":"02252184421162584539"}},"outputId":"81152430-4ecf-4a29-e2bc-d4273374ffe2"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stderr","text":["Evaluating exercises:   3%|▎         | 1/34 [00:18<10:14, 18.63s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: affine-cipher\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:   6%|▌         | 2/34 [00:32<08:33, 16.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: beer-song\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:   9%|▉         | 3/34 [00:51<08:59, 17.41s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: book-store\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  12%|█▏        | 4/34 [01:06<08:03, 16.12s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: bottle-song\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  15%|█▍        | 5/34 [01:27<08:47, 18.20s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: bowling\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  18%|█▊        | 6/34 [01:46<08:29, 18.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: connect\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  21%|██        | 7/34 [02:00<07:37, 16.94s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: dominoes\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  24%|██▎       | 8/34 [02:32<09:23, 21.68s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: dot-dsl\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  26%|██▋       | 9/34 [02:53<08:58, 21.54s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: food-chain\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  29%|██▉       | 10/34 [03:18<08:59, 22.49s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: forth\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  32%|███▏      | 11/34 [03:34<07:55, 20.66s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: go-counting\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  35%|███▌      | 12/34 [03:50<07:03, 19.23s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: grade-school\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  38%|███▊      | 13/34 [04:09<06:42, 19.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: grep\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  41%|████      | 14/34 [04:21<05:40, 17.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: hangman\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  44%|████▍     | 15/34 [04:38<05:24, 17.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: list-ops\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  47%|████▋     | 16/34 [05:02<05:40, 18.91s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: paasio\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  50%|█████     | 17/34 [05:20<05:19, 18.79s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: phone-number\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  53%|█████▎    | 18/34 [05:37<04:50, 18.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: pig-latin\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  56%|█████▌    | 19/34 [05:59<04:50, 19.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Failed: poker\n","Generation failed: Error code: 503 - {'error': {'message': 'Provider returned error', 'code': 503, 'metadata': {'raw': '{\"detail\":\"No instances available (yet) for chute_id=\\'6275d63c-ca84-56f2-81c1-93a4070c6348\\'\"}', 'provider_name': 'Chutes'}}, 'user_id': 'user_34T64NRW09AE1IOhHpOs4qHu0F8'}\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  59%|█████▉    | 20/34 [06:08<03:48, 16.35s/it]"]},{"output_type":"stream","name":"stdout","text":["No code generated for pov\n","Generation failed: Error code: 503 - {'error': {'message': 'Provider returned error', 'code': 503, 'metadata': {'raw': '{\"detail\":\"No instances available (yet) for chute_id=\\'6275d63c-ca84-56f2-81c1-93a4070c6348\\'\"}', 'provider_name': 'Chutes'}}, 'user_id': 'user_34T64NRW09AE1IOhHpOs4qHu0F8'}\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  62%|██████▏   | 21/34 [06:20<03:15, 15.01s/it]"]},{"output_type":"stream","name":"stdout","text":["No code generated for proverb\n","Generation failed: Error code: 503 - {'error': {'message': 'Provider returned error', 'code': 503, 'metadata': {'raw': '{\"detail\":\"No instances available (yet) for chute_id=\\'6275d63c-ca84-56f2-81c1-93a4070c6348\\'\"}', 'provider_name': 'Chutes'}}, 'user_id': 'user_34T64NRW09AE1IOhHpOs4qHu0F8'}\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  65%|██████▍   | 22/34 [06:28<02:34, 12.87s/it]"]},{"output_type":"stream","name":"stdout","text":["No code generated for react\n","Generation failed: Error code: 503 - {'error': {'message': 'Provider returned error', 'code': 503, 'metadata': {'raw': '{\"detail\":\"No instances available (yet) for chute_id=\\'6275d63c-ca84-56f2-81c1-93a4070c6348\\'\"}', 'provider_name': 'Chutes'}}, 'user_id': 'user_34T64NRW09AE1IOhHpOs4qHu0F8'}\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  68%|██████▊   | 23/34 [06:36<02:05, 11.45s/it]"]},{"output_type":"stream","name":"stdout","text":["No code generated for rest-api\n","Generation failed: Error code: 503 - {'error': {'message': 'Provider returned error', 'code': 503, 'metadata': {'raw': '{\"detail\":\"No instances available (yet) for chute_id=\\'6275d63c-ca84-56f2-81c1-93a4070c6348\\'\"}', 'provider_name': 'Chutes'}}, 'user_id': 'user_34T64NRW09AE1IOhHpOs4qHu0F8'}\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  71%|███████   | 24/34 [06:48<01:55, 11.60s/it]"]},{"output_type":"stream","name":"stdout","text":["No code generated for robot-name\n","Generation failed: Error code: 503 - {'error': {'message': 'Provider returned error', 'code': 503, 'metadata': {'raw': '{\"detail\":\"No instances available (yet) for chute_id=\\'6275d63c-ca84-56f2-81c1-93a4070c6348\\'\"}', 'provider_name': 'Chutes'}}, 'user_id': 'user_34T64NRW09AE1IOhHpOs4qHu0F8'}\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  74%|███████▎  | 25/34 [06:56<01:34, 10.47s/it]"]},{"output_type":"stream","name":"stdout","text":["No code generated for scale-generator\n","Generation failed: Error code: 503 - {'error': {'message': 'Provider returned error', 'code': 503, 'metadata': {'raw': '{\"detail\":\"No instances available (yet) for chute_id=\\'6275d63c-ca84-56f2-81c1-93a4070c6348\\'\"}', 'provider_name': 'Chutes'}}, 'user_id': 'user_34T64NRW09AE1IOhHpOs4qHu0F8'}\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  76%|███████▋  | 26/34 [07:04<01:17,  9.69s/it]"]},{"output_type":"stream","name":"stdout","text":["No code generated for sgf-parsing\n","Generation failed: Error code: 503 - {'error': {'message': 'Provider returned error', 'code': 503, 'metadata': {'raw': '{\"detail\":\"No instances available (yet) for chute_id=\\'6275d63c-ca84-56f2-81c1-93a4070c6348\\'\"}', 'provider_name': 'Chutes'}}, 'user_id': 'user_34T64NRW09AE1IOhHpOs4qHu0F8'}\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  79%|███████▉  | 27/34 [07:12<01:03,  9.10s/it]"]},{"output_type":"stream","name":"stdout","text":["No code generated for simple-linked-list\n","Generation failed: Error code: 503 - {'error': {'message': 'Provider returned error', 'code': 503, 'metadata': {'raw': '{\"detail\":\"No instances available (yet) for chute_id=\\'6275d63c-ca84-56f2-81c1-93a4070c6348\\'\"}', 'provider_name': 'Chutes'}}, 'user_id': 'user_34T64NRW09AE1IOhHpOs4qHu0F8'}\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  82%|████████▏ | 28/34 [07:19<00:52,  8.74s/it]"]},{"output_type":"stream","name":"stdout","text":["No code generated for transpose\n","Generation failed: Error code: 503 - {'error': {'message': 'Provider returned error', 'code': 503, 'metadata': {'raw': '{\"detail\":\"No instances available (yet) for chute_id=\\'6275d63c-ca84-56f2-81c1-93a4070c6348\\'\"}', 'provider_name': 'Chutes'}}, 'user_id': 'user_34T64NRW09AE1IOhHpOs4qHu0F8'}\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  85%|████████▌ | 29/34 [07:27<00:42,  8.49s/it]"]},{"output_type":"stream","name":"stdout","text":["No code generated for tree-building\n","Generation failed: Error code: 503 - {'error': {'message': 'Provider returned error', 'code': 503, 'metadata': {'raw': '{\"detail\":\"No instances available (yet) for chute_id=\\'6275d63c-ca84-56f2-81c1-93a4070c6348\\'\"}', 'provider_name': 'Chutes'}}, 'user_id': 'user_34T64NRW09AE1IOhHpOs4qHu0F8'}\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  88%|████████▊ | 30/34 [07:36<00:33,  8.39s/it]"]},{"output_type":"stream","name":"stdout","text":["No code generated for two-bucket\n","Generation failed: Error code: 503 - {'error': {'message': 'Provider returned error', 'code': 503, 'metadata': {'raw': '{\"detail\":\"No instances available (yet) for chute_id=\\'6275d63c-ca84-56f2-81c1-93a4070c6348\\'\"}', 'provider_name': 'Chutes'}}, 'user_id': 'user_34T64NRW09AE1IOhHpOs4qHu0F8'}\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  91%|█████████ | 31/34 [07:43<00:24,  8.14s/it]"]},{"output_type":"stream","name":"stdout","text":["No code generated for variable-length-quantity\n","Generation failed: Error code: 503 - {'error': {'message': 'Provider returned error', 'code': 503, 'metadata': {'raw': '{\"detail\":\"No instances available (yet) for chute_id=\\'6275d63c-ca84-56f2-81c1-93a4070c6348\\'\"}', 'provider_name': 'Chutes'}}, 'user_id': 'user_34T64NRW09AE1IOhHpOs4qHu0F8'}\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  94%|█████████▍| 32/34 [07:51<00:16,  8.21s/it]"]},{"output_type":"stream","name":"stdout","text":["No code generated for wordy\n","Generation failed: Error code: 429 - {'error': {'message': 'Rate limit exceeded: free-models-per-min. ', 'code': 429, 'metadata': {'headers': {'X-RateLimit-Limit': '20', 'X-RateLimit-Remaining': '0', 'X-RateLimit-Reset': '1761316140000'}, 'provider_name': None}}, 'user_id': 'user_34T64NRW09AE1IOhHpOs4qHu0F8'}\n"]},{"output_type":"stream","name":"stderr","text":["\rEvaluating exercises:  97%|█████████▋| 33/34 [07:59<00:08,  8.16s/it]"]},{"output_type":"stream","name":"stdout","text":["No code generated for zebra-puzzle\n","Generation failed: Error code: 503 - {'error': {'message': 'Provider returned error', 'code': 503, 'metadata': {'raw': '{\"detail\":\"No instances available (yet) for chute_id=\\'6275d63c-ca84-56f2-81c1-93a4070c6348\\'\"}', 'provider_name': 'Chutes'}}, 'user_id': 'user_34T64NRW09AE1IOhHpOs4qHu0F8'}\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating exercises: 100%|██████████| 34/34 [08:07<00:00, 14.33s/it]"]},{"output_type":"stream","name":"stdout","text":["No code generated for zipper\n","\n","Accuracy: 0.00%  (0/34 exercises passed)\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["!cat \"/content/drive/MyDrive/devstral/paasio.py\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t09mkJI6mBp0","executionInfo":{"status":"ok","timestamp":1761317407599,"user_tz":-120,"elapsed":167,"user":{"displayName":"hamidreza bahmanyar","userId":"02252184421162584539"}},"outputId":"a84169cb-c3e1-42c3-a106-6bf68b0434d0"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["def report_io_statistics(file, sock):\n","    \"\"\"\n","    Reports network IO statistics.\n","\n","    Args:\n","        file (file object): The file object to report IO statistics for.\n","        sock (socket object): The socket object to report IO statistics for.\n","\n","    Returns:\n","        tuple: A tuple containing the total number of bytes read, the total number of bytes written, and the total number of operations.\n","    \"\"\"\n","    total_bytes_read = 0\n","    total_bytes_written = 0\n","    total_operations = 0\n","\n","    # Iterate over each chunk in the file object\n","    for chunk in file:\n","        # Increment the total bytes read by the length of the chunk\n","        total_bytes_read += len(chunk)\n","        # Increment the total operations by 1\n","        total_operations += 1\n","\n","    # Iterate over each chunk in the socket object\n","    for chunk in sock:\n","        # Increment the total bytes written by the length of the chunk\n","        total_bytes_written += len(chunk)\n","        # Increment the total operations by 1\n","        total_operations += 1\n","\n","    # Check if total operations is zero to avoid division by zero error\n","    if total_operations == 0:\n","        raise ValueError(\"Total operations cannot be zero.\")\n","\n","    # Return the total bytes read, total bytes written, and total operations\n","    return total_bytes_read, total_bytes_written, total_operations"]}]},{"cell_type":"code","source":["import os\n","\n","\n","os.environ['GITHUB_TOKEN'] = \"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\"\n","username = \"H4miiiid\"\n","repo = \"MentorApp\"\n","\n","!git clone https://{username}:${{GITHUB_TOKEN}}@github.com/{username}/{repo}.git\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hXji-afWorc4","executionInfo":{"status":"ok","timestamp":1761657866242,"user_tz":-60,"elapsed":1228,"user":{"displayName":"hamidreza bahmanyar","userId":"02252184421162584539"}},"outputId":"6c5b22d8-e0e4-4566-c615-9f61f36bb94c"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'MentorApp'...\n","remote: Enumerating objects: 3, done.\u001b[K\n","remote: Counting objects: 100% (3/3), done.\u001b[K\n","remote: Compressing objects: 100% (2/2), done.\u001b[K\n","remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (3/3), done.\n"]}]},{"cell_type":"code","source":["%cd MentorApp\n","!cp /content/your_notebook.ipynb .\n","!git config --global user.email \"hamidbhy7@gmail.com\"\n","!git config --global user.name \"H4miiiid\"\n","!git add LLM_model_and_benchmarks.ipynb\n","!git commit -m \"Add Colab notebook\"\n","!git push https://{username}:${{GITHUB_TOKEN}}@github.com/{username}/{repo}.git\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ZJNA5at-7Mv","executionInfo":{"status":"ok","timestamp":1761657993760,"user_tz":-60,"elapsed":1267,"user":{"displayName":"hamidreza bahmanyar","userId":"02252184421162584539"}},"outputId":"02f32ce9-42fd-46c5-deb7-ca68f75bbdab"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/MentorApp\n","cp: cannot stat '/content/your_notebook.ipynb': No such file or directory\n","fatal: pathspec 'LLM_model_and_benchmarks.ipynb' did not match any files\n","On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","nothing to commit, working tree clean\n","Everything up-to-date\n"]}]},{"cell_type":"code","source":["!ls /content/drive/MyDrive\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RjYhDq1c_7O0","executionInfo":{"status":"ok","timestamp":1761658238199,"user_tz":-60,"elapsed":763,"user":{"displayName":"hamidreza bahmanyar","userId":"02252184421162584539"}},"outputId":"06fc1bf7-f20e-4627-e598-c97ffe68b776"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":[" 412408966957_T_HEBN1000084483400300.PDF.792384949.pdf.zip\n"," Aa.gslides\n","'assignment 1-nlp'\n"," AssignmentsIPCV\n"," best_model_SaveModel_format.keras\n","'Colab Notebooks'\n"," DatiPers.gsheet\n"," devstral\n","'Image processing'\n"," invoice-2414217682.pdf\n"," LabSessionsIPCV\n"," LLM_model\n"," LLM_Models\n"," MentorMap_AI_FOCUS.pdf\n","'modello delega consegna e ritiro documenti-bahmanyar-signless.gdoc'\n"," Network-Lab\n"," Piano_di_Studi_Hamidreza_Bahmanyar.pdf\n"," polyglot-benchmark\n"," PyTorch-Tutorial\n"," ROOMS.xlsx\n"," transaction-confirmation-report_en-us_02c981.pdf\n"]}]},{"cell_type":"code","source":["!ls /content/drive/MyDrive/Colab\\ Notebooks"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HrIX4jzeASzM","executionInfo":{"status":"ok","timestamp":1761658411763,"user_tz":-60,"elapsed":130,"user":{"displayName":"hamidreza bahmanyar","userId":"02252184421162584539"}},"outputId":"a46ec586-d5e0-4cb8-f036-9b85465d9eaa"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":[" 00_PyTorch_Fundamentals.ipynb\n"," 00_tensorflow_fundamentals.ipynb\n"," 01_Neural_Network_Regression_with_Tensorflow.ipynb\n"," 01_PyTorch_workflow.ipynb\n"," 02_neural_network_classification_with_tensorflow.ipynb\n"," 03_pytorch_computer_vision.ipynb\n","'Assignment1-2425 (1).ipynb'\n","'Assignment1_2425_(2)-2.ipynb'\n","'Assignment1-2425 (2).ipynb'\n","'Assignment1_2425 (2).ipynb'\n"," Assignment1-2425.ipynb\n"," Assignment1_2425.ipynb\n"," assignment1_IPCV_2_GPTipynb.ipynb\n","'assignment2 (1).ipynb'\n","'assignment2 (2).ipynb'\n"," assignment2.ipynb\n","'assignment_module_one (1).ipynb'\n"," assignment_module_one.ipynb\n"," assignment_module_two.ipynb\n"," Book_detection_Cursor.ipynb\n"," book_detection_sift.ipynb\n"," Bookshelves_Cursor.ipynb\n"," dataset_preparation.ipynb\n","'final_version_a2 (1).ipynb'\n"," final_version_a2.ipynb\n"," hamidreza_bahmanyar.ipynb\n"," Homework1_Bahmanyar.ipynb\n"," homework2_1_Bahmanyar.ipynb\n"," homework2_2_Bahmanyar.ipynb\n"," homework2_3_Bahmanyar.ipynb\n"," homework3_GD_Bahmanyar.ipynb\n"," homework3_gradient.ipynb\n"," homework3_SGD_Bahmanyar.ipynb\n"," homework3_SGD.ipynb\n"," Homework4_Bahmanyar.ipynb\n"," Homework4.ipynb\n"," lab2a_intro.ipynb\n","'lab2a-intro-nocode (1).ipynb'\n","'lab2a-intro-nocode (2).ipynb'\n"," lab2a-intro-nocode.ipynb\n","'lab2b-data-exploration (1).ipynb'\n"," lab2b-data-exploration.ipynb\n"," lab2b-data-exploration-nocode.ipynb\n","'lab3a-class-dt-hold-out (1).ipynb'\n","'lab3a-class-dt-hold-out (2) (1).ipynb'\n","'lab3a-class-dt-hold-out (2).ipynb'\n"," lab3a-class-dt-hold-out.ipynb\n","'lab3b-class-dt-grid-search-cv (1).ipynb'\n"," lab3b-class-dt-grid-search-cv.ipynb\n"," lab3b-class-dt-grid-search-cv_nocode.ipynb\n","'lab3c-using-several-class (1).ipynb'\n","'lab3c-using-several-class (2).ipynb'\n","'lab3c-using-several-class (3).ipynb'\n"," lab3c-using-several-class.ipynb\n","'lab3c-using-several-class-nocode (1).ipynb'\n"," lab3c-using-several-class-nocode.ipynb\n","'lab4a-regression_example (1).ipynb'\n","'lab4a-regression_example (2).ipynb'\n"," lab4a-regression_example.ipynb\n","'lab4b_polynomial_regression_temp_power_compact (1).ipynb'\n"," lab4b_polynomial_regression_temp_power_compact.ipynb\n"," lab4-polynomial_regression_temp_power_nocode.ipynb\n"," lab4-regression_example_nocode.ipynb\n"," lab5a_pca_nocode.ipynb\n","'lab5a_pca_solution (1).ipynb'\n","'lab5a_pca_solution (2).ipynb'\n"," lab5a_pca_solution.ipynb\n"," lab5b_select-kbest_nocode.ipynb\n","'lab5b_select-kbest_solution (1).ipynb'\n"," lab5b_select-kbest_solution.ipynb\n","'lab5-task-assignment (1).ipynb'\n","'lab5-task-assignment (2).ipynb'\n"," lab5-task-assignment.ipynb\n","'lab6-clustering_kmeans_agglom_dbscan_wholesale (1).ipynb'\n","'lab6-clustering_kmeans_agglom_dbscan_wholesale (2).ipynb'\n"," lab6-clustering_kmeans_agglom_dbscan_wholesale.ipynb\n"," lab6-clustering_kmeans_agglom_dbscan_wholesale_nocode.ipynb\n","'lab_session_1 (1).ipynb'\n","'lab_session_1 (2).ipynb'\n"," lab_session_1.ipynb\n","'lab_session_2 (1).ipynb'\n"," lab_session_2.ipynb\n"," lab_session_2_solutions.ipynb\n"," lab_session_3.ipynb\n"," lab_session_5.ipynb\n"," LLM_model_and_benchmarks.ipynb\n","'lstm (1).ipynb'\n"," lstm.ipynb\n","'machineLearning-07-association-rules (1).ipynb'\n","'machineLearning-07-association-rules (2).ipynb'\n","'machineLearning-07-association-rules (3).ipynb'\n"," machineLearning-07-association-rules.ipynb\n"," Malaria_project.ipynb\n"," mistral7b_llm_model.ipynb\n","'[NLP_2425]_Assignment_2 (1).ipynb'\n","'[NLP_2425]_Assignment_2 (3).ipynb'\n","'openai_gpt5_context_engineering(test).ipynb'\n"," Pandas.ipynb\n","'Sentence_Reordering_spec (1).ipynb'\n","'Sentence_Reordering_spec (2).ipynb'\n","'Sentence_Reordering_spec (5).ipynb'\n"," Sentence_Reordering_spec.ipynb\n"," tutorial1-2324.ipynb\n"," tutorial2-2425.ipynb\n"," Untitled\n"," Untitled0.ipynb\n","'Untitled (1)'\n"," Untitled10.ipynb\n"," Untitled11.ipynb\n"," Untitled12.ipynb\n"," Untitled13.ipynb\n"," Untitled14.ipynb\n"," Untitled15.ipynb\n"," Untitled16.ipynb\n"," Untitled17.ipynb\n"," Untitled18.ipynb\n"," Untitled19.ipynb\n"," Untitled1.ipynb\n","'Untitled (2)'\n"," Untitled20.ipynb\n"," Untitled21.ipynb\n"," Untitled22.ipynb\n"," Untitled2.ipynb\n","'Untitled (3)'\n"," Untitled3.ipynb\n","'Untitled (4)'\n"," Untitled4.ipynb\n","'Untitled (5)'\n"," Untitled5.ipynb\n","'Untitled (6)'\n"," Untitled6.ipynb\n","'Untitled (7)'\n"," Untitled7.ipynb\n","'Untitled (8)'\n"," Untitled8.ipynb\n","'Untitled (9)'\n"," Untitled9.ipynb\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"-b3MsPOXBhjp"},"execution_count":null,"outputs":[]}]}
