{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyOdT37cGabBkxxXEY5jaD0s"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"id":"0CmgoMnluG1Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## This is the test file to generate 10 samples (description + code) in JSON format with different models."],"metadata":{"id":"eWREQ6kyUoWI"}},{"cell_type":"markdown","source":["## A. Generate project descriptions and titles with three different models"],"metadata":{"id":"HfK-afzwXPZU"}},{"cell_type":"markdown","source":["### 1. Setup the GPT-5 model and OpenRouter API key"],"metadata":{"id":"ElC6Hg0L9q8F"}},{"cell_type":"code","source":["!pip -q install requests jsonschema"],"metadata":{"id":"S5uFmQWFVKMt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os, json, re, textwrap, datetime\n","import requests\n","from jsonschema import Draft7Validator\n","\n","OPENROUTER_API_KEY = \"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\"\n","MODELS = [\n","    #\"openai/gpt-5\",\n","    \"anthropic/claude-sonnet-4.5\",\n","    \"qwen/qwen3-coder\",\n","]"],"metadata":{"id":"K0l84vbFVFOK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2. Set the variables"],"metadata":{"id":"OO1bcsPjWvXd"}},{"cell_type":"code","source":["SYSTEM_PROMPT = \"\"\"\n","You are a meticulous AI project designer.\n","Your job: produce concise, implementable AI mini-project ideas.\n","\n","Rules:\n","- Output must be valid JSON ONLY (no extra text).\n","- Each item has exactly two keys: \"title\" and \"description\".\n","- Titles are short and specific (≤ 6 words).\n","- Descriptions are 1–2 sentences, concrete, and implementable offline in 20–60 minutes.\n","- Prefer single-file, single-metric projects with tiny data and fast runtime.\n","- Avoid duplicate or near-duplicate ideas.\n","- Prefer standard Python libs or widely used ML libs (numpy, pandas, scikit-learn, PyTorch, TensorFlow, OpenCV).\n","- No external downloads; use built-in toy datasets (e.g., sklearn iris/digits) or tiny synthetic data.\n","\"\"\".strip()\n"],"metadata":{"id":"5vOUmWY-V7b6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["FEW_SHOTS = \"\"\"\n","{\"title\":\"Iris SVM CLI\",\n"," \"description\":\"Train a small SVM on sklearn's iris dataset and print test accuracy. Provide a --predict flag that accepts four comma-separated features and prints the predicted class.\"}\n","{\"title\":\"Canny Edge CLI\",\n"," \"description\":\"Load an image path or generate a 128×128 synthetic image, run OpenCV Canny with --t1/--t2 thresholds, save edges.png, and print TEST_PASS if the edge map is non-empty.\"}\n","\"\"\".strip()\n"],"metadata":{"id":"jkZyHY39Wi0b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3. A function for describing the task"],"metadata":{"id":"3heZju0CXrbG"}},{"cell_type":"code","source":["import textwrap\n","\n","def build_task(n=10):\n","    return textwrap.dedent(f\"\"\"\n","    Task: Generate {n} distinct AI mini-project ideas.\n","\n","    Constraints:\n","    - Return a JSON array of length {n}.\n","    - Each item: object with exactly \"title\" (string) and \"description\" (string).\n","    - No comments, no prose outside JSON.\n","\n","    Scope & Simplicity:\n","    - Each project is doable offline in 20–60 minutes on CPU.\n","    - Single-file mindset: one clear goal, one primary metric or artifact.\n","    - Keep dependencies minimal (numpy/pandas/sklearn/torch/tf/opencv only).\n","\n","    Data:\n","    - Do NOT require internet downloads.\n","    - Use built-in toy datasets (e.g., sklearn iris/digits) or tiny synthetic data generation.\n","    - If an image/text input is needed, allow a synthetic fallback.\n","\n","    Focus areas ONLY:\n","    - NLP, CV, Tabular. Do not include TimeSeries or Audio.\n","\n","    Description style:\n","    - Titles ≤ 6 words, specific.\n","    - Descriptions are 1–2 sentences with concrete I/O hints (flags, paths, outputs).\n","    - Include at least one quick validation (e.g., accuracy threshold, file existence, non-empty output).\n","\n","    Diversity (within the allowed areas):\n","    - Avoid repeating the same idea or trivial variants.\n","\n","    Follow the style of these examples without repeating them:\n","    {FEW_SHOTS}\n","\n","    Now produce the JSON array of {n} items.\n","    \"\"\").strip()\n"],"metadata":{"id":"6-5DGgCOXZjl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 4. OpenRouter call helper"],"metadata":{"id":"Fp4QApEQXwmt"}},{"cell_type":"code","source":["# Helper to make a safe Python variable name from a slug\n","def varname_from_slug(slug: str) -> str:\n","    name = slug.lower().replace(\"/\", \"_\").replace(\"-\", \"_\").replace(\".\", \"_\")\n","    return f\"{name}_result\""],"metadata":{"id":"NzPyoCu1N0-S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Generic OpenRouter caller taking model_id\n","def call_openrouter_model(model_id, messages, temperature=0.2, top_p=0.9, max_tokens=6000):\n","    url = \"https://openrouter.ai/api/v1/chat/completions\"\n","    headers = {\n","        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n","        \"Content-Type\": \"application/json\",\n","        \"HTTP-Referer\": \"https://colab.research.google.com/\",\n","        \"X-Title\": f\"Multi-Model Project Generator\",\n","    }\n","    payload = {\n","        \"model\": model_id,\n","        \"messages\": messages,\n","        \"temperature\": float(temperature),\n","        \"top_p\": float(top_p),\n","        \"max_tokens\": int(max_tokens),\n","    }\n","    t0 = time.time()\n","    r = requests.post(url, headers=headers, json=payload, timeout=120)\n","    latency = time.time() - t0\n","    r.raise_for_status()\n","    content = r.json()[\"choices\"][0][\"message\"][\"content\"]\n","    return content, latency"],"metadata":{"id":"rWSuWp7WMSRz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Validator for title/description array\n","from jsonschema import Draft7Validator\n","def validate_items(arr, N):\n","    ITEM_SCHEMA = {\n","        \"type\":\"object\",\n","        \"required\":[\"title\",\"description\"],\n","        \"properties\":{\n","            \"title\":{\"type\":\"string\",\"minLength\":3, \"maxLength\":100},\n","            \"description\":{\"type\":\"string\",\"minLength\":20, \"maxLength\":600}\n","        },\n","        \"additionalProperties\": False\n","    }\n","    ARRAY_SCHEMA = {\"type\":\"array\",\"items\":ITEM_SCHEMA, \"minItems\":N, \"maxItems\":N}\n","    errs = [e.message for e in Draft7Validator(ARRAY_SCHEMA).iter_errors(arr)]\n","    titles = [ (x.get(\"title\") or \"\").strip().lower() for x in arr ]\n","    if len(set(titles)) != len(titles):\n","        errs.append(\"Duplicate titles detected.\")\n","    return errs"],"metadata":{"id":"Vf2XvtJbOCqB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Robust extractor (keeps your previous logic)\n","import re, json, time, requests\n","def extract_json_array(text: str):\n","    m = re.search(r\"```(?:json)?\\s*([\\s\\S]*?)\\s*```\", text, re.IGNORECASE)\n","    if m:\n","        text = m.group(1).strip()\n","    start = text.find('[')\n","    if start == -1:\n","        return None\n","    depth = 0\n","    for i in range(start, len(text)):\n","        ch = text[i]\n","        if ch == '[': depth += 1\n","        elif ch == ']':\n","            depth -= 1\n","            if depth == 0:\n","                return text[start:i+1]\n","    return None"],"metadata":{"id":"FPYRGxi3OGxS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Build a single shared message set\n","N = 10\n","task = build_task(N) + \"\\n\\nReturn a raw JSON array only — no prose, no code fences, no markdown.\"\n","messages = [\n","    {\"role\":\"system\",\"content\": SYSTEM_PROMPT},\n","    {\"role\":\"user\",\"content\": task}\n","]\n","\n","# Loop models and create a separate variable per model with the results\n","for model_id in MODELS:\n","    print(f\"\\n===== {model_id} =====\")\n","    varname = varname_from_slug(model_id)         # e.g. \"openai_gpt_5_result\"\n","    try:\n","        raw, secs = call_openrouter_model(model_id, messages, temperature=0.2)\n","        json_str = extract_json_array(raw)\n","        if not json_str:\n","            globals()[varname] = {\n","                \"raw\": raw, \"json_str\": None, \"items\": None,\n","                \"errors\": [\"No JSON array found\"], \"latency\": secs\n","            }\n","            print(f\"❌ No JSON array found | {secs:.1f}s\")\n","            continue\n","\n","        items = json.loads(json_str)\n","        errors = validate_items(items, N)\n","\n","        globals()[varname] = {\n","            \"raw\": raw, \"json_str\": json_str, \"items\": items,\n","            \"errors\": errors, \"latency\": secs\n","        }\n","\n","        if errors:\n","            print(f\"⚠️ Parsed but validation errors ({len(errors)}) | {secs:.1f}s\")\n","            for e in errors[:5]:\n","                print(\" -\", e)\n","        else:\n","            print(f\"✅ Valid JSON ({len(items)} items) | {secs:.1f}s\")\n","            print(json.dumps(items[:2], indent=2, ensure_ascii=False))  # preview first 2\n","    except Exception as e:\n","        globals()[varname] = {\n","            \"raw\": None, \"json_str\": None, \"items\": None,\n","            \"errors\": [str(e)], \"latency\": None\n","        }\n","        print(\"❌ Exception:\", e)"],"metadata":{"id":"UoWEsUznP-wi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for model_id in MODELS:\n","    print(\" -\", varname_from_slug(model_id))"],"metadata":{"id":"AEr6Y84rbtaM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### All the resuts for three models that I used are below:"],"metadata":{"id":"4lC6XKaeW9ZR"}},{"cell_type":"code","source":["print(json.dumps(anthropic_claude_sonnet_4_5_result['items'], indent=2, ensure_ascii=False))"],"metadata":{"id":"mXqi-EmWRcja"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(json.dumps(qwen_qwen3_coder_result['items'], indent=2, ensure_ascii=False))"],"metadata":{"id":"Fv0RTeu2Ur29"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. Generating the codes for each projects that have been generated earlier with the models"],"metadata":{"id":"HXJrkTU-XJ3w"}},{"cell_type":"code","source":["# -------- External memory (compact, curated) --------\n","memory = {\n","  \"style_guide\": [\n","    \"Single-file script with `if __name__ == '__main__':` entrypoint.\",\n","    \"Use argparse with clear --help and sensible defaults.\",\n","    \"Prefer standard library datasets (sklearn, torchvision, keras).\",\n","    \"Attempt auto-download/cache with short timeout; if unavailable, fallback to a tiny structured synthetic dataset.\",\n","    \"Fix randomness: set seeds for random, numpy; torch if used; run on CPU by default.\",\n","    \"Validate inputs (paths, columns, image loads) and fail gracefully with one-line reason.\",\n","    \"Keep runtime < 2 minutes (few epochs, small subsets).\",\n","    \"Print `TEST_PASS` on success; otherwise `TEST_FAIL: <reason>`.\"\n","  ],\n","  \"lessons\": [\n","    \"When standardizing features use sklearn.pipeline.Pipeline to avoid leakage.\",\n","    \"For OpenCV Canny, expose --threshold1 and --threshold2; convert to grayscale before edges.\",\n","    \"For CSV tasks, explicitly validate required columns; show a friendly error if missing.\",\n","    \"For plotting, save figures to disk and plt.close() to avoid backend issues.\",\n","    \"One file only. Return exactly ONE ```python block. No extra prose.\",\n","    \"CLI + help. Use a single 'argparse.ArgumentParser()'. All help strings are single-line (no embedded newlines).\",\n","    \"Seeds in 'main()'. Expose '--seed' and set seeds for random, numpy, and torch (if present) inside main().\",\n","    \"Data access policy. Only use library datasets when --allow-download is passed. Otherwise do not download; use a robust fallback (sklearn tabular, torchvision FakeData, PIL shapes, etc.). If using 20NG, call with download_if_missing=False unless allowed.\",\n","    \"Task–dataset match. Choose datasets that match the task (e.g., do not use 20 Newsgroups for spam/ham).\",\n","    \"CV safety. For OpenCV: 1. convert to grayscale if needed. 2. ensure input to detectors is uint8 (cv2.convertScaleAbs if needed). 3. for Haar, check face_cascade.empty() == False or fail.\",\n","    \"Acceptance contract. Implement explicit pass/fail checks (files exist, metrics ≥ thresholds, non-empty edge map, etc.). Print TEST_PASS only when all conditions hold; otherwise TEST_FAIL: <reason> and sys.exit(1).\",\n","    \"No broken syntax. Never split identifiers across lines. Never break f-strings or string literals across lines.\",\n","    \"End marker. Append '# END_OF_SCRIPT' as the last line of the file.\"\n","  ],\n","  \"snippets\": [\n","    # seed block to embed in each script\n","    \"import random, numpy as np\\nrandom.seed(42)\\nnp.random.seed(42)\\ntry:\\n    import torch\\n    torch.manual_seed(42)\\nexcept Exception:\\n    pass\"\n","  ]\n","}"],"metadata":{"id":"9lD2Trr6Ux6B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["SYSTEM_PROMPT_CODEGEN = \"\"\"\n","You are a meticulous senior Python engineer who writes production-quality, runnable scripts.\n","Priorities: (1) correctness, (2) reproducibility, (3) clarity, (4) speed.\n","\n","Formatting & Output Contract:\n","- Return ONE code block only: ```python ...```\n","- The code must be a single file with `if __name__ == \"__main__\":` entrypoint.\n","- Provide a clear CLI via argparse and `--help`. All help strings must be single-line (no embedded newlines).\n","- Do not print explanations. Do not include markdown outside the single code block.\n","- Append `# END_OF_SCRIPT` as the final line of the file.\n","\n","Data Access Policy:\n","- Prefer standard, library-provided datasets that Colab typically caches:\n","  - sklearn.datasets (iris, wine, diabetes, digits)\n","  - torchvision.datasets (MNIST, FashionMNIST, CIFAR-10/100)\n","  - tensorflow.keras.datasets (mnist, cifar10/cifar100, imdb, reuters)\n","- Only attempt loading/auto-downloading these datasets when the user passes `--allow-download`.\n","- If `--allow-download` is not passed, do NOT download; immediately fall back to a robust local/synthetic option\n","  (e.g., sklearn tabular, torchvision FakeData, PIL-drawn shapes, sklearn digits).\n","- For sklearn 20 Newsgroups, call with `download_if_missing=False` unless `--allow-download` is passed.\n","- Use small subsets and few epochs to keep runtime < 2 minutes.\n","- Do not call arbitrary external URLs or third-party APIs.\n","\n","Behavioral Rules:\n","- Expose `--seed` and set seeds **inside `main()`** for `random`, `numpy`, and `torch` (if available); run on CPU by default.\n","- Choose datasets that match the task semantics (e.g., do NOT use 20 Newsgroups for spam/ham).\n","- Validate inputs (paths, columns, image loads, audio length) and fail gracefully with a concise message.\n","- For OpenCV tasks: convert to grayscale when needed; ensure `uint8` input (use `cv2.convertScaleAbs` if necessary);\n","  for Haar cascades, ensure `face_cascade.empty() == False` or fail.\n","- Keep the code minimal, readable, and fully runnable in a fresh Colab.\n","- Never split identifiers across lines; never break string literals or f-strings across lines.\n","- Implement explicit acceptance checks tied to the task (files exist, metrics ≥ thresholds, non-empty edge map, etc.).\n","- Print `TEST_PASS` only when all acceptance conditions hold; otherwise print `TEST_FAIL: <reason>` and `sys.exit(1)`.\n","\n","Self-Check Before Returning (silently revise if any item fails):\n","- argparse help strings are single-line.\n","- Seeds are applied in `main()` for random/numpy/torch.\n","- No downloads unless `--allow-download` is passed; otherwise robust fallback is used.\n","- Dataset matches task semantics.\n","- Acceptance checks implemented; `TEST_PASS`/`TEST_FAIL` behavior present.\n","- File ends with `# END_OF_SCRIPT`.\n","- Code parses without SyntaxError.\n","\"\"\".strip()\n"],"metadata":{"id":"dTqjD9yBhJ6O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["FEWSHOTS_CODE = \"\"\"\n","Example A (tabular classification with sklearn iris -> fallback synthetic; seeds-in-main; single-line help; acceptance checks)\n","```python\n","import argparse, sys\n","import random, numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","\n","def load_iris_or_synthetic(seed=42):\n","    try:\n","        from sklearn.datasets import load_iris  # no download required\n","        data = load_iris()\n","        X, y, used = data.data, data.target, \"iris\"\n","    except Exception:\n","        rng = np.random.default_rng(seed)\n","        n = 210\n","        c = rng.integers(0, 3, size=n)\n","        X = rng.normal(0, 1, size=(n, 4)) + c[:, None] * 1.5\n","        y, used = c, \"synthetic\"\n","    return X, y, used\n","\n","def main():\n","    p = argparse.ArgumentParser(description=\"Iris (no-download) or synthetic fallback; seeds set in main; explicit acceptance.\")\n","    p.add_argument(\"--test-size\", type=float, default=0.2, help=\"Test set fraction (default: 0.2).\")\n","    p.add_argument(\"--seed\", type=int, default=42, help=\"Random seed (default: 42).\")\n","    args = p.parse_args()\n","\n","    # seeds in main\n","    random.seed(args.seed); np.random.seed(args.seed)\n","    try:\n","        import torch; torch.manual_seed(args.seed)\n","    except Exception:\n","        pass\n","\n","    X, y, used = load_iris_or_synthetic(args.seed)\n","    if X is None or y is None or len(X) == 0:\n","        print(\"TEST_FAIL: dataset not available\"); sys.exit(1)\n","\n","    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=args.test_size, random_state=args.seed, stratify=y)\n","    clf = Pipeline([(\"scaler\", StandardScaler()), (\"lr\", LogisticRegression(max_iter=300))])\n","    clf.fit(Xtr, ytr)\n","    acc = clf.score(Xte, yte)\n","    print(f\"dataset={used} accuracy={acc:.3f}\")\n","    # acceptance: stricter if iris, looser if synthetic\n","    if acc >= (0.85 if used == \"iris\" else 0.70):\n","        print(\"TEST_PASS\")\n","    else:\n","        print(\"TEST_FAIL: accuracy below threshold\"); sys.exit(1)\n","\n","if __name__ == \"__main__\":\n","    main()\n","# END_OF_SCRIPT\n","```\n","\n","Example B (vision MNIST with opt-in download -> fallback FakeData; uint8 safety; seeds-in-main; acceptance checks)\n","```python\n","import argparse, sys, os\n","import random, numpy as np\n","\n","def load_mnist_or_fakedata(max_train=2000, max_test=500, seed=42, allow_download=False):\n","    try:\n","        import torch\n","        from torchvision import datasets, transforms\n","        torch.manual_seed(seed)\n","        tfm = transforms.ToTensor()\n","        # only download if explicitly allowed\n","        train = datasets.MNIST(root=\"./data\", train=True, download=bool(allow_download), transform=tfm)\n","        test  = datasets.MNIST(root=\"./data\", train=False, download=bool(allow_download), transform=tfm)\n","        # if dataset objects are empty because cache missing and download disabled, trigger fallback\n","        if len(train) == 0 or len(test) == 0:\n","            raise RuntimeError(\"MNIST cache missing and download disabled\")\n","        train = torch.utils.data.Subset(train, list(range(min(len(train), max_train))))\n","        test  = torch.utils.data.Subset(test,  list(range(min(len(test),  max_test))))\n","        return train, test, True\n","    except Exception:\n","        import torch\n","        from torchvision import transforms\n","        from torchvision.datasets import FakeData\n","        torch.manual_seed(seed)\n","        tfm = transforms.ToTensor()\n","        train = FakeData(size=max_train, image_size=(1, 28, 28), num_classes=10, transform=tfm)\n","        test  = FakeData(size=max_test,  image_size=(1, 28, 28), num_classes=10, transform=tfm)\n","        return train, test, False\n","\n","def main():\n","    import torch\n","    import torch.nn as nn\n","    import torch.optim as optim\n","    from torch.utils.data import DataLoader\n","\n","    p = argparse.ArgumentParser(description=\"MNIST (opt-in download) or FakeData fallback; seeds in main; explicit acceptance.\")\n","    p.add_argument(\"--epochs\", type=int, default=1, help=\"Training epochs (default: 1).\")\n","    p.add_argument(\"--batch\", type=int, default=128, help=\"Batch size (default: 128).\")\n","    p.add_argument(\"--seed\", type=int, default=42, help=\"Random seed (default: 42).\")\n","    p.add_argument(\"--allow-download\", action=\"store_true\", help=\"Permit MNIST download if not cached.\")\n","    args = p.parse_args()\n","\n","    # seeds in main\n","    random.seed(args.seed); np.random.seed(args.seed); torch.manual_seed(args.seed)\n","\n","    train_ds, test_ds, real = load_mnist_or_fakedata(seed=args.seed, allow_download=args.allow_download)\n","    train = DataLoader(train_ds, batch_size=args.batch, shuffle=True)\n","    test  = DataLoader(test_ds,  batch_size=args.batch, shuffle=False)\n","\n","    class TinyCNN(nn.Module):\n","        def __init__(self):\n","            super().__init__()\n","            self.net = nn.Sequential(\n","                nn.Conv2d(1, 16, 3, 1), nn.ReLU(),\n","                nn.MaxPool2d(2),\n","                nn.Conv2d(16, 32, 3, 1), nn.ReLU(),\n","                nn.MaxPool2d(2),\n","                nn.Flatten(),\n","                nn.Linear(32*5*5, 64), nn.ReLU(),\n","                nn.Linear(64, 10)\n","            )\n","        def forward(self, x): return self.net(x)\n","\n","    model = TinyCNN()\n","    opt = optim.Adam(model.parameters(), lr=1e-3)\n","    loss_fn = nn.CrossEntropyLoss()\n","\n","    model.train()\n","    for _ in range(args.epochs):\n","        for xb, yb in train:\n","            # ensure uint8 -> float32 is handled by ToTensor; just train\n","            opt.zero_grad()\n","            logits = model(xb)\n","            loss = loss_fn(logits, yb)\n","            loss.backward(); opt.step()\n","\n","    # eval + acceptance\n","    model.eval()\n","    correct = total = 0\n","    with torch.no_grad():\n","        for xb, yb in test:\n","            pred = model(xb).argmax(1)\n","            correct += (pred == yb).sum().item()\n","            total += yb.numel()\n","    acc = correct / max(total, 1)\n","    print(f\"acc={acc:.3f} dataset={'mnist' if real else 'fake'}\")\n","    # stricter if real, looser if fake\n","    if acc >= (0.85 if real else 0.20):\n","        print(\"TEST_PASS\")\n","    else:\n","        print(\"TEST_FAIL: accuracy below threshold\"); sys.exit(1)\n","\n","if __name__ == \"__main__\":\n","    main()\n","# END_OF_SCRIPT\n","```\n","\"\"\".strip()"],"metadata":{"id":"Zfk26-lPhjg-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os, re, json, requests\n","\n","# --- helpers ---\n","def extract_code_block(text: str) -> str:\n","    \"\"\"\n","    Return the first code block content if present; otherwise return the whole text.\n","    Prefers ```python ... ``` but accepts ``` ... ```.\n","    \"\"\"\n","    m = re.search(r\"```(?:python)?\\s*([\\s\\S]*?)\\s*```\", text, re.IGNORECASE)\n","    return m.group(1) if m else text\n","\n","def print_long(s: str, width: int = 4000):\n","    \"\"\"Print long strings without Colab truncation, in chunks.\"\"\"\n","    for i in range(0, len(s), width):\n","        print(s[i:i+width])"],"metadata":{"id":"OqSL3SvAmQsI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# -------- Task builder (per project) --------\n","def build_code_task(project, memory):\n","    guide = \"\\n- \".join(memory[\"style_guide\"])\n","    lessons = \"\\n- \".join(memory[\"lessons\"][-6:])\n","    seed_block = memory[\"snippets\"][0]\n","\n","    return f\"\"\"\n","    PROJECT TITLE:\n","    {project['title']}\n","\n","    PROJECT DESCRIPTION:\n","    {project['description']}\n","\n","    Follow this style guide:\n","    - {guide}\n","\n","    Incorporate recent lessons:\n","    - {lessons}\n","\n","    Hard guardrails (must follow):\n","    - Return ONE code block only: ```python ...``` (no extra prose).\n","    - Single file with `if __name__ == \"__main__\":` entrypoint.\n","    - Use argparse; **all help strings are single-line** (no embedded newlines).\n","    - Expose `--seed` and set seeds **inside `main()`** for random, numpy, and torch (if available).\n","    - **Data policy:** Only attempt library dataset downloads when `--allow-download` is passed. Otherwise DO NOT download; use a robust fallback suited to this task (e.g., sklearn tabular, torchvision FakeData, PIL-drawn shapes, sklearn digits).\n","    - If using sklearn 20 Newsgroups, call with `download_if_missing=False` unless `--allow-download` is passed.\n","    - Choose datasets that **match the task semantics** (e.g., do NOT use 20 Newsgroups for spam/ham).\n","    - For OpenCV tasks: convert to grayscale when needed; ensure `uint8` input (use `cv2.convertScaleAbs` if necessary); for Haar cascades verify `face_cascade.empty()==False` or fail.\n","    - Never split identifiers across lines; never break string literals or f-strings across lines.\n","\n","    Embed this seed block near the top of the script:\n","    ```python\n","    {seed_block}\"\"\"\n"],"metadata":{"id":"GAf1N6exiOEE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# -------- OpenRouter caller (model passed in) --------\n","\n","def call_openrouter_model(model_id, messages, temperature=0.2, top_p=0.9, max_tokens=7000):\n","  url = \"https://openrouter.ai/api/v1/chat/completions\"\n","  headers = {\n","  \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n","  \"Content-Type\": \"application/json\",\n","  \"HTTP-Referer\": \"https://colab.research.google.com/\",\n","  \"X-Title\": \"Code Generation (per-model)\",\n","  }\n","  if not headers[\"Authorization\"]:\n","    raise RuntimeError(\"OPENROUTER_API_KEY environment variable not set.\")\n","  payload = {\n","    \"model\": model_id,\n","    \"messages\": messages,\n","    \"temperature\": float(temperature),\n","    \"top_p\": float(top_p),\n","    \"max_tokens\": int(max_tokens),\n","    }\n","  r = requests.post(url, headers=headers, json=payload, timeout=120)\n","  r.raise_for_status()\n","  return r.json()[\"choices\"][0][\"message\"][\"content\"]"],"metadata":{"id":"o4q9n4p5itoy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-------- Map: model slug -> per-model dict variable name --------\n","\n","MODEL_TO_RESULTVAR = {\n","#\"openai/gpt-5\": \"openai_gpt_5_result\",\n","\"anthropic/claude-sonnet-4.5\": \"anthropic_claude_sonnet_4_5_result\" ,\n","\"qwen/qwen3-coder\": \"qwen_qwen3_coder_result\"\n","}"],"metadata":{"id":"jhRCCtsKjETU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# -------- Generate code for the first 2 projects per model --------\n","\n","print(\"Generating code for first 2 items of each model's projects...\\n\")\n","per_model_generated_code = {}\n","\n","def code_items_varname(slug: str) -> str:\n","    return slug.lower().replace(\"/\", \"_\").replace(\"-\", \"_\").replace(\".\", \"_\") + \"_code_items\"\n","\n","\n","for model_id, varname in MODEL_TO_RESULTVAR.items():\n","    result = globals().get(varname)\n","    if not result or not result.get(\"items\"):\n","        print(f\"Skipping {model_id}: no items found in `{varname}`\")\n","        continue\n","\n","    projects = result[\"items\"][:2]  # first 2 only for test\n","    print(f\"\\n===== {model_id}: generating and attaching code for {len(projects)} projects =====\")\n","\n","    items_with_code = []\n","    for idx, proj in enumerate(projects, 1):\n","        messages = [\n","            {\"role\": \"system\", \"content\": SYSTEM_PROMPT_CODEGEN},\n","            {\"role\": \"user\", \"content\": \"Study these two short code examples and copy their structure (CLI, dataset policy, seeds, TEST_PASS contract).\"},\n","            {\"role\": \"assistant\", \"content\": FEWSHOTS_CODE},\n","            {\"role\": \"user\", \"content\": build_code_task(proj, memory)},\n","        ]\n","        raw = call_openrouter_model(model_id, messages, temperature=0.2, max_tokens=7000)\n","        code = extract_code_block(raw)\n","\n","        item = {\n","            \"title\": proj[\"title\"],\n","            \"description\": proj[\"description\"],\n","            \"code\": code\n","        }\n","        items_with_code.append(item)\n","\n","        # show the full code (no truncation)\n","        print(f\"\\n--- {model_id} • Project {idx}: {proj['title']} ---\\n\")\n","        print_long(code)  # full code printed\n","\n","    # put per-model list into a dedicated variable\n","    var_codes = code_items_varname(model_id)  # e.g., openai_gpt_5_code_items\n","    globals()[var_codes] = items_with_code\n","\n","    # also store inside the original result dict under 'items_with_code' for convenience\n","    result[\"items_with_code\"] = items_with_code\n","\n","    # pretty JSON view of the per-model list\n","    print(f\"\\n>>> {model_id} • JSON with title, description, code:\")\n","    print_long(json.dumps(items_with_code, indent=2, ensure_ascii=False))"],"metadata":{"id":"S6ZV3JUYkuZW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(json.dumps(qwen_qwen3_coder_result[\"items_with_code\"], indent=2, ensure_ascii=False))"],"metadata":{"id":"quVj0XmEp_95"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Note:** So now we have more structured and more correct project codes and descriptions that before which they are acceptable for finetuning the smaller models."],"metadata":{"id":"Pnro2mqpboNm"}},{"cell_type":"code","source":["import os\n","\n","os.environ['GITHUB_TOKEN'] = \"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\"\n","username = \"H4miiiid\"\n","repo = \"MentorApp\"\n","\n","!git clone https://{username}:${{GITHUB_TOKEN}}@github.com/{username}/{repo}.git /content/MentorApp\n"],"metadata":{"id":"SBOIDV2OtJbR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp \"/content/drive/MyDrive/Colab Notebooks/models_context_engineering(project_codes).ipynb\" /content/MentorApp/\n","\n","\n","\n","\n"],"metadata":{"id":"KtP6yqQzti43"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git config --global user.email \"hamidbhy7@gmail.com\"\n","!git config --global user.name \"H4miiiid\"\n"],"metadata":{"id":"q_q5g3K3v-On"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cd /content/MentorApp && git add \"models_context_engineering(test).ipynb\"\n","!cd /content/MentorApp && git commit -m \"Add models_context_engineering(test).ipynb notebook from Drive\"\n","!cd /content/MentorApp && git push https://{username}:${{GITHUB_TOKEN}}@github.com/{username}/{repo}.git\n","\n"],"metadata":{"id":"oqNhTEZPtpmF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"4DvN254Xvmpg"},"execution_count":null,"outputs":[]}]}